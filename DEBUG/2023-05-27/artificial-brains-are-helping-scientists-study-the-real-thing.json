{"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/artificial-brains-are-helping-scientists-study-the-real-thing", "__typename": "URL"}, "__typename": "Content", "id": "/content/s70jg56mccbk8pqgigooqsqi96l4v78f", "tegID": "s70jg56mccbk8pqgigooqsqi96l4v78f", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Artificial brains are helping scientists study the real thing", "subheadline": "Neuroscience and AI", "seoPageTitle": null, "seoMetadataDescription": null, "ad": {"grapeshot": {"channels": [{"name": "gv_safe", "score": 14416.932, "__typename": "GrapeshotChannel"}, {"name": "future_of_work_test", "score": 4.896, "__typename": "GrapeshotChannel"}, {"name": "neg_omd_exclusion", "score": 3.014, "__typename": "GrapeshotChannel"}, {"name": "gb_safe", "score": 2.815, "__typename": "GrapeshotChannel"}, {"name": "gs_science_misc", "score": 2.804, "__typename": "GrapeshotChannel"}, {"name": "gs_tech", "score": 2.685, "__typename": "GrapeshotChannel"}, {"name": "gt_positive", "score": 2.17, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_computing", "score": 2.164, "__typename": "GrapeshotChannel"}, {"name": "gs_education", "score": 2.002, "__typename": "GrapeshotChannel"}, {"name": "gt_positive_curiosity", "score": 1.848, "__typename": "GrapeshotChannel"}, {"name": "ibm_cloud", "score": 1.701, "__typename": "GrapeshotChannel"}, {"name": "education_university", "score": 1.674, "__typename": "GrapeshotChannel"}, {"name": "gs_education_university", "score": 1.674, "__typename": "GrapeshotChannel"}, {"name": "ts_tech", "score": 1.67, "__typename": "GrapeshotChannel"}, {"name": "neg_3166_vca_brand-safety", "score": 1.321, "__typename": "GrapeshotChannel"}, {"name": "neg_3166_vca_brand-safety3", "score": 1.321, "__typename": "GrapeshotChannel"}, {"name": "society_highereducation_university", "score": 1.301, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_ai", "score": 1.264, "__typename": "GrapeshotChannel"}, {"name": "artificial_intelligence", "score": 1.231, "__typename": "GrapeshotChannel"}, {"name": "custom_punkt", "score": 1.216, "__typename": "GrapeshotChannel"}, {"name": "chanel_neg", "score": 1.216, "__typename": "GrapeshotChannel"}, {"name": "google_negative_keywords", "score": 1.208, "__typename": "GrapeshotChannel"}, {"name": "ge_tech_enthusiasts", "score": 1.178, "__typename": "GrapeshotChannel"}, {"name": "gs_science", "score": 1.129, "__typename": "GrapeshotChannel"}, {"name": "america_department_education", "score": 1.105, "__typename": "GrapeshotChannel"}, {"name": "test_mba", "score": 1.099, "__typename": "GrapeshotChannel"}, {"name": "it_decisionmakers", "score": 1.064, "__typename": "GrapeshotChannel"}, {"name": "it_professionals", "score": 1.064, "__typename": "GrapeshotChannel"}, {"name": "gs_pets", "score": 1.012, "__typename": "GrapeshotChannel"}, {"name": "america_department_commerce", "score": 0.994, "__typename": "GrapeshotChannel"}, {"name": "ibm_blacklist", "score": 0.984, "__typename": "GrapeshotChannel"}, {"name": "gs_health", "score": 0.962, "__typename": "GrapeshotChannel"}], "__typename": "Grapeshot"}, "__typename": "Ad"}, "audio": {"main": null, "__typename": "Media"}, "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_STD001.jpg", "__typename": "URL"}, "__typename": "Content", "height": 720, "width": 1280, "description": ""}, "promo": null, "__typename": "Media"}, "description": "No model is perfect. But that doesn\u2019t stop them being useful", "datePublished": "2023-05-24T17:33:19Z", "dateModified": "2023-05-25T13:11:23Z", "dateRevised": "2023-05-24T17:33:19Z", "dateRevisedString": "May 24th 2023", "datePublishedString": "May 24th 2023", "dateCreated": "2023-05-24T10:31:12Z", "copyrightYear": 2023, "inLanguage": "en", "byline": "", "dateline": null, "text": [{"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "span", "attribs": {"data-caps": "initial"}, "children": [{"data": "T", "type": "text"}]}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "he striking", "type": "text"}]}, {"data": " progress in artificial intelligence over the past decade is mostly down to advances in machine learning, whereby computers teach themselves complicated tasks by crunching large quantities of data, rather than having to be programmed directly by humans. This approach has driven rapid progress in computer vision, language translation and, most recently, the human-like conversational skills of chatbots such as ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": "-4. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The learning is done by software models called \u201cartificial neural networks\u201d (", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANNs", "type": "text"}]}, {"data": "). The standard description of an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " is that it is loosely inspired by the networks of neurons in the human brain. It is ", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "de rigueur", "type": "text"}]}, {"data": " to follow that description with an immediate disclaimer, in which both computer scientists and neuroscientists jump in nervously to point out that the analogy is very rough, that ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s are mere cartoons of real brains (if even that) and that they fail to capture the complexity of the biological organ.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "All that is true. But some neuroscientists are beginning to find that even cartoons can be useful. The inner workings of the best ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s\u2014those that are closest to matching human performance on tasks like identifying objects, or responding to text prompts\u2014appear to have some remarkable similarities to the workings of brains. Having taken inspiration from biology, in other words, programmers are now returning the favour, with their creations telling neuroscientists useful things about biological brains. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The seminal study comparing brains and ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s was published in ", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "Proceedings of the National Academy of Sciences", "type": "text"}]}, {"data": " in 2014. Daniel Yamins, a neuroscientist at the Massachusetts Institute of Technology (", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "MIT", "type": "text"}]}, {"data": "), and his colleagues trained an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " to pick out objects from photographs\u2014a cat, for instance. The researchers compared what was going on inside the electronic network to what was happening inside the brains of macaque monkeys that had been set the same task, and whose brains had been wired with electrodes. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s are built up from large numbers of artificial neurons that, just like their natural counterparts, can be on or off; firing or silent. These neurons are linked together in layered, interconnected networks. Activity in lower layers can affect how neurons in the higher layers fire. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Inside the black box", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Dr Yamins\u2019s test involves image recognition, which in natural brains proceeds hierarchically. One layer of neurons will detect simple features such as patches of light or dark. A higher layer organises those into edges; a still higher layer combines the edges into shapes. That process of increasing abstraction continues until, eventually, the brain decides whether it is looking at a cat, a dog or a banana. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Images that share some characteristics provoke similar clusters of neurons to fire. If a certain set of neurons fires when looking at a cat, another, partially overlapping set is likely to fire in response to a picture of a dog. The neurons that respond to both images are thought to be representing features\u2014fur, four legs and a tail, say\u2014that are present in both pictures. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "When Dr Yamins and his colleagues compared what was going on inside the macaque brains to the silicon ones, they found arresting parallels between how the monkeys represented images and how the computers did. \u201cThe paper was a game-changer,\u201d says Nancy Kanwisher, another professor at ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "MIT", "type": "text"}]}, {"data": " who has spent much of her career studying the human visual system, and who now uses ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s in some of her research. \u201cThe [artificial] network was not in any way designed to fit the brain. It was just designed to solve the problem and yet we see this incredible fit.\u201d", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Since then, whenever an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " model has close to human performance on a task, neuroscientists have been eager to compare it with natural brains. They have found similarities between ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s trained to recognise speech and process language, such as those used in transcription software, and the human auditory cortex. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The pattern holds for written language too. One paper published in 2021 compared human brain activity against many different commercial language models. It found that the most sophisticated ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "\u2014at the time Open", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "\u2019s ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": "-2\u2014was the closest match for human brain activity. The better models get at solving certain tasks, the more similar they seem to get to the human brain doing the same.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Another indication that the analogy between artificial neural networks and natural ones is useful is that the study of the former can make testable predictions about the latter. A paper published in 2022, by researchers at Columbia University and ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "MIT", "type": "text"}]}, {"data": ", found that an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " trained on image-recognition tasks produced a group of artificial neurons devoted to classifying foodstuffs specifically. When the paper was published there was, as far as anyone knew, no analogous area of the human visual system. But the following year researchers from the same laboratory announced that they had discovered a region of the human brain that does indeed contain neurons that fire more often when a person is shown pictures of food.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Perhaps the strongest evidence for the claim that artificial brains can reveal useful things about biological ones is the apparent ability for software and wetware to interact with each other directly. Nicholas Sexton and Bradley Love, a pair of neuroscientists of University College London, started out rather sceptical about the supposed resemblance between natural and artificial neural networks. Simply seeing similar patterns of activity, they argued, was not enough to claim that ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s and brains were solving problems in the same way. To prove that the correspondence was meaningful, they suggested investigating whether it was possible to feed brain activity into an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": ".", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "In 2022 they published a paper in ", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "Science Advances", "type": "text"}]}, {"data": " that did just that. The researchers fed an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " trained to recognise images data recorded by an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "MRI", "type": "text"}]}, {"data": " scanner examining human brains. The idea was to try to let the", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": " ANN", "type": "text"}]}, {"data": " \u201csee\u201d through human eyes. Sure enough, the hotwired ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " was able to interpret data from any of the hierarchical layers of the biological visual system\u2014though it did best with data from the higher levels, which had already been partly processed by the brain in question. If the computer model was shown brain activity from a human that was looking at a picture of a greyhound, for example, then it would say that it was looking at a greyhound\u2014as opposed to some other object\u2014almost 70% of the time. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The fact that a silicon brain can happily accept half-chewed data from a biological one suggests that, on some level, the two systems are performing the same sort of cognitive task. That insight might prove useful for brain-computer interfaces, which are devices that aim to allow biological brains to talk directly to machines. An ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " linked up to a camera, for instance, might be used to feed partly processed visual information into the brain. That might help treat some forms of blindness caused by damage to the brain\u2019s visual system. Several different research groups in Europe and America are already testing that idea in experiments on macaques.", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Models of the mind", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Even those most enthusiastic about ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s do not argue they are perfect analogues of the human brain. Some make mistakes that humans never would\u2014give an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " a picture of a cat but with the skin of an elephant, for example, and the model is more likely to identify it as an elephant. But no scientific model is ever perfect. The question is whether it is useful. One of neuroscience\u2019s problems is that experiments are difficult to run, for both ethical and practical reasons. Poking and prodding ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": "s could offer a useful alternative. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "In any case, comparing biology and silicon continues to produce intriguing results. In a paper published in May researchers from the University of Texas at Austin used a neural network to monitor brain signals from participants in an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "MRI", "type": "text"}]}, {"data": " scanner. Using just data from the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "mri", "type": "text"}]}, {"data": ", the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "ANN", "type": "text"}]}, {"data": " could produce a rough summary of a story that the test subject was listening to, a description of a film they were watching, or the gist of a sentence they were imagining. \u201cWhen I was in graduate school I would dream about something like this existing,\u201d says Dr Love. \u201cI thought it would be hundreds of years until we had something that works this well.\u201d ", "type": "text"}, {"type": "tag", "name": "span", "attribs": {"data-ornament": "ufinish"}, "children": [{"data": "\u25a0", "type": "text"}]}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "Curious about the world? To enjoy our mind-expanding science coverage, sign up to ", "type": "text"}, {"type": "tag", "name": "a", "attribs": {"href": "https://www.economist.com/newsletters/simply-science"}, "children": [{"data": "Simply Science", "type": "text"}]}, {"data": ", our weekly subscriber-only newsletter.", "type": "text"}]}]}], "bodyText": "The striking progress in artificial intelligence over the past decade is mostly down to advances in machine learning, whereby computers teach themselves complicated tasks by crunching large quantities of data, rather than having to be programmed directly by humans. This approach has driven rapid progress in computer vision, language translation and, most recently, the human-like conversational skills of chatbots such as GPT-4. \nThe learning is done by software models called \u201cartificial neural networks\u201d (ANNs). The standard description of an ANN is that it is loosely inspired by the networks of neurons in the human brain. It is de rigueur to follow that description with an immediate disclaimer, in which both computer scientists and neuroscientists jump in nervously to point out that the analogy is very rough, that ANNs are mere cartoons of real brains (if even that) and that they fail to capture the complexity of the biological organ.\nAll that is true. But some neuroscientists are beginning to find that even cartoons can be useful. The inner workings of the best ANNs\u2014those that are closest to matching human performance on tasks like identifying objects, or responding to text prompts\u2014appear to have some remarkable similarities to the workings of brains. Having taken inspiration from biology, in other words, programmers are now returning the favour, with their creations telling neuroscientists useful things about biological brains. \nThe seminal study comparing brains and ANNs was published in Proceedings of the National Academy of Sciences in 2014. Daniel Yamins, a neuroscientist at the Massachusetts Institute of Technology (MIT), and his colleagues trained an ANN to pick out objects from photographs\u2014a cat, for instance. The researchers compared what was going on inside the electronic network to what was happening inside the brains of macaque monkeys that had been set the same task, and whose brains had been wired with electrodes. \nANNs are built up from large numbers of artificial neurons that, just like their natural counterparts, can be on or off; firing or silent. These neurons are linked together in layered, interconnected networks. Activity in lower layers can affect how neurons in the higher layers fire. \nInside the black box\nDr Yamins\u2019s test involves image recognition, which in natural brains proceeds hierarchically. One layer of neurons will detect simple features such as patches of light or dark. A higher layer organises those into edges; a still higher layer combines the edges into shapes. That process of increasing abstraction continues until, eventually, the brain decides whether it is looking at a cat, a dog or a banana. \nImages that share some characteristics provoke similar clusters of neurons to fire. If a certain set of neurons fires when looking at a cat, another, partially overlapping set is likely to fire in response to a picture of a dog. The neurons that respond to both images are thought to be representing features\u2014fur, four legs and a tail, say\u2014that are present in both pictures. \nWhen Dr Yamins and his colleagues compared what was going on inside the macaque brains to the silicon ones, they found arresting parallels between how the monkeys represented images and how the computers did. \u201cThe paper was a game-changer,\u201d says Nancy Kanwisher, another professor at MIT who has spent much of her career studying the human visual system, and who now uses ANNs in some of her research. \u201cThe [artificial] network was not in any way designed to fit the brain. It was just designed to solve the problem and yet we see this incredible fit.\u201d\nSince then, whenever an ANN model has close to human performance on a task, neuroscientists have been eager to compare it with natural brains. They have found similarities between ANNs trained to recognise speech and process language, such as those used in transcription software, and the human auditory cortex. \nThe pattern holds for written language too. One paper published in 2021 compared human brain activity against many different commercial language models. It found that the most sophisticated ANN\u2014at the time OpenAI\u2019s GPT-2\u2014was the closest match for human brain activity. The better models get at solving certain tasks, the more similar they seem to get to the human brain doing the same.\nAnother indication that the analogy between artificial neural networks and natural ones is useful is that the study of the former can make testable predictions about the latter. A paper published in 2022, by researchers at Columbia University and MIT, found that an ANN trained on image-recognition tasks produced a group of artificial neurons devoted to classifying foodstuffs specifically. When the paper was published there was, as far as anyone knew, no analogous area of the human visual system. But the following year researchers from the same laboratory announced that they had discovered a region of the human brain that does indeed contain neurons that fire more often when a person is shown pictures of food.\nPerhaps the strongest evidence for the claim that artificial brains can reveal useful things about biological ones is the apparent ability for software and wetware to interact with each other directly. Nicholas Sexton and Bradley Love, a pair of neuroscientists of University College London, started out rather sceptical about the supposed resemblance between natural and artificial neural networks. Simply seeing similar patterns of activity, they argued, was not enough to claim that ANNs and brains were solving problems in the same way. To prove that the correspondence was meaningful, they suggested investigating whether it was possible to feed brain activity into an ANN.\nIn 2022 they published a paper in Science Advances that did just that. The researchers fed an ANN trained to recognise images data recorded by an MRI scanner examining human brains. The idea was to try to let the ANN \u201csee\u201d through human eyes. Sure enough, the hotwired ANN was able to interpret data from any of the hierarchical layers of the biological visual system\u2014though it did best with data from the higher levels, which had already been partly processed by the brain in question. If the computer model was shown brain activity from a human that was looking at a picture of a greyhound, for example, then it would say that it was looking at a greyhound\u2014as opposed to some other object\u2014almost 70% of the time. \nThe fact that a silicon brain can happily accept half-chewed data from a biological one suggests that, on some level, the two systems are performing the same sort of cognitive task. That insight might prove useful for brain-computer interfaces, which are devices that aim to allow biological brains to talk directly to machines. An ANN linked up to a camera, for instance, might be used to feed partly processed visual information into the brain. That might help treat some forms of blindness caused by damage to the brain\u2019s visual system. Several different research groups in Europe and America are already testing that idea in experiments on macaques.\nModels of the mind\nEven those most enthusiastic about ANNs do not argue they are perfect analogues of the human brain. Some make mistakes that humans never would\u2014give an ANN a picture of a cat but with the skin of an elephant, for example, and the model is more likely to identify it as an elephant. But no scientific model is ever perfect. The question is whether it is useful. One of neuroscience\u2019s problems is that experiments are difficult to run, for both ethical and practical reasons. Poking and prodding ANNs could offer a useful alternative. \nIn any case, comparing biology and silicon continues to produce intriguing results. In a paper published in May researchers from the University of Texas at Austin used a neural network to monitor brain signals from participants in an MRI scanner. Using just data from the mri, the ANN could produce a rough summary of a story that the test subject was listening to, a description of a film they were watching, or the gist of a sentence they were imagining. \u201cWhen I was in graduate school I would dream about something like this existing,\u201d says Dr Love. \u201cI thought it would be hundreds of years until we had something that works this well.\u201d  \u25a0\nCurious about the world? To enjoy our mind-expanding science coverage, sign up to Simply Science, our weekly subscriber-only newsletter.", "about": {"public": null, "__typename": "Taxonomies"}, "print": {"headline": "Brains in a box", "section": {"url": {"canonical": "https://www.economist.com/science-and-technology/", "__typename": "URL"}, "__typename": "Content", "headline": "Science & technology"}, "__typename": "Print"}, "articleSection": {"public": null, "internal": [{"url": {"canonical": "https://www.economist.com/science-and-technology/", "__typename": "URL"}, "__typename": "Content", "id": "/content/0q9q05sn1pkml185ggkt9md42em318ff", "tegID": "0q9q05sn1pkml185ggkt9md42em318ff", "headline": "Science & technology", "hasPart": {"parts": [{"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/why-venetians-are-pondering-raising-their-entire-city", "__typename": "URL"}, "__typename": "Content", "id": "/content/rqdi7uqpemsbnl5f26iq1cqfnmuvde60", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Why Venetians are pondering raising their entire city", "subheadline": "Saving Venice", "datePublished": "2023-05-24T17:33:54Z", "description": "A \u20ac5.5bn flood barrier has bought only a temporary reprieve", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_STP003.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/artificial-brains-are-helping-scientists-study-the-real-thing", "__typename": "URL"}, "__typename": "Content", "id": "/content/s70jg56mccbk8pqgigooqsqi96l4v78f", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Artificial brains are helping scientists study the real thing", "subheadline": "Neuroscience and AI", "datePublished": "2023-05-24T17:33:19Z", "description": "No model is perfect. But that doesn\u2019t stop them being useful", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_STD001.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/old-tyres-can-become-a-climate-friendly-fuel", "__typename": "URL"}, "__typename": "Content", "id": "/content/p6d5p86paclflfempmm5s5ven42bkaig", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Old tyres can become a climate-friendly fuel", "subheadline": "Recycling old tyres", "datePublished": "2023-05-24T17:32:28Z", "description": "Getting fuel from your wheels", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_STP001.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/parenting-can-be-bad-for-the-kids", "__typename": "URL"}, "__typename": "Content", "id": "/content/1qos3jsl1r3g3egdarpnvk54r6hghiq3", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Parenting can be bad for the kids", "subheadline": "Helicopter beetles", "datePublished": "2023-05-24T17:29:43Z", "description": "At least, from a genetic point of view", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_STP002.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/17/the-coming-years-will-be-the-hottest-ever", "__typename": "URL"}, "__typename": "Content", "id": "/content/50stju4t1c4i1qpn51julmoseh3i2e0q", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "The coming years will be the hottest ever", "subheadline": "Mercury rising", "datePublished": "2023-05-17T20:11:14Z", "description": "The world could soon breach its 1.5\u00b0C target for global warming", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230520_STP502.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}], "__typename": "HasPart"}}], "__typename": "Taxonomies"}, "publication": [{"url": {"canonical": "https://www.economist.com/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/0ahcf9cn8l22qr8nr6rfn2sqtc5d9h59", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AF", "AS", "AU", "BD", "BT", "BN", "KH", "CN", "CK", "FJ", "GU", "PF", "HK", "IN", "ID", "JP", "KI", "KP", "KR", "LA", "MO", "MY", "MV", "MH", "FM", "MN", "MM", "NR", "NP", "NC", "NZ", "PK", "PG", "PH", "PN", "SC", "SG", "SB", "LK", "TF", "TW", "TH", "TO", "TV", "VU", "VN", "IO", "CC", "TL", "HM", "NU", "NF", "MP", "PW", "WS", "CX", "TK", "WF"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "Behold the national treasure: How to fix the NHS", "width": 1280, "height": 1684, "regionsAllowed": ["UK", "GB", "GG", "IM", "JE"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/eu/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/134udl9j50scig3q9m2516gr6q75r5mr", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/ap/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/s413ogt6tm4l7t13gh0psj7t0ov54lno", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AF", "AS", "AU", "BD", "BT", "BN", "KH", "CN", "CK", "FJ", "GU", "PF", "HK", "IN", "ID", "JP", "KI", "KP", "KR", "LA", "MO", "MY", "MV", "MH", "FM", "MN", "MM", "NR", "NP", "NC", "NZ", "PK", "PG", "PH", "PN", "SC", "SG", "SB", "LK", "TF", "TW", "TH", "TO", "TV", "VU", "VN", "IO", "CC", "TL", "HM", "NU", "NF", "MP", "PW", "WS", "CX", "TK", "WF"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/la/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/r148cgbtpn8r95kap4kb814ldbbofc2c", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/me/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/a9saae6o0e109j8560qfqj82kogau71b", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/uk/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/o04190oq39a9tue8vjis18ius96kn1mk", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "Behold the national treasure: How to fix the NHS", "width": 1280, "height": 1684, "regionsAllowed": ["UK", "GB", "GG", "IM", "JE"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/na/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/23ni04hsk3d1ahu1j20tqnjho7tfj36o", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/a/printedition/2023-05-27", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: MAY 27TH 2023", "description": "", "subheadline": "", "datePublished": "2023-05-27T00:00:00Z", "datePublishedString": "May 27th 2023", "id": "/content/050fcck58a4kilbnqmp37mdbrsnsiup8", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "The haunting", "width": 1280, "height": 1684, "regionsAllowed": ["AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230527_DE_SQ_EU.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}], "channel": {"tegID": "j53t6hsedat4l7rkbb1le98u73262sh5", "__typename": "Content"}, "_metadata": {"articleId": "/content/s70jg56mccbk8pqgigooqsqi96l4v78f", "tegID": "s70jg56mccbk8pqgigooqsqi96l4v78f", "title": "Neuroscience and AI - Artificial brains are helping scientists study the real thing | Science & technology | The Economist", "shareSnippet": "Neuroscience and AI \u2013 Artificial brains are helping scientists study the real thing", "headline": "Artificial brains are helping scientists study the real thing", "section": "Science & technology", "keywords": [], "author": ["The Economist"], "url": "https://www.economist.com/science-and-technology/2023/05/24/artificial-brains-are-helping-scientists-study-the-real-thing", "type": "Article", "articleBody": "The striking progress in artificial intelligence over the past decade is mostly down to advances in machine learning, whereby computers teach themselves complicated tasks by crunching large quantities of data, rather than having to be programmed directly by humans. This approach has driven rapid progress in computer vision, language translation and, most recently, the human-like conversational skills of chatbots such as GPT-4. \nThe learning is done by software models called \u201cartificial neural networks\u201d (ANNs). The standard description of an ANN is that it is loosely inspired by the networks of neurons in the human brain. It is de rigueur to follow that description with an immediate disclaimer, in which both computer scientists and neuroscientists jump in nervously to point out that the analogy is very rough, that ANNs are mere cartoons of real brains (if even that) and that they fail to capture the complexity of the biological organ.\nAll that is true. But some neuroscientists are beginning to find that even cartoons can be useful. The inner workings of the best ANNs\u2014those that are closest to matching human performance on tasks like identifying objects, or responding to text prompts\u2014appear to have some remarkable similarities to the workings of brains. Having taken inspiration from biology, in other words, programmers are now returning the favour, with their creations telling neuroscientists useful things about biological brains. \nThe seminal study comparing brains and ANNs was published in Proceedings of the National Academy of Sciences in 2014. Daniel Yamins, a neuroscientist at the Massachusetts Institute of Technology (MIT), and his colleagues trained an ANN to pick out objects from photographs\u2014a cat, for instance. The researchers compared what was going on inside the electronic network to what was happening inside the brains of macaque monkeys that had been set the same task, and whose brains had been wired with electrodes. \nANNs are built up from large numbers of artificial neurons that, just like their natural counterparts, can be on or off; firing or silent. These neurons are linked together in layered, interconnected networks. Activity in lower layers can affect how neurons in the higher layers fire. \nInside the black box\nDr Yamins\u2019s test involves image recognition, which in natural brains proceeds hierarchically. One layer of neurons will detect simple features such as patches of light or dark. A higher layer organises those into edges; a still higher layer combines the edges into shapes. That process of increasing abstraction continues until, eventually, the brain decides whether it is looking at a cat, a dog or a banana. \nImages that share some characteristics provoke similar clusters of neurons to fire. If a certain set of neurons fires when looking at a cat, another, partially overlapping set is likely to fire in response to a picture of a dog. The neurons that respond to both images are thought to be representing features\u2014fur, four legs and a tail, say\u2014that are present in both pictures. \nWhen Dr Yamins and his colleagues compared what was going on inside the macaque brains to the silicon ones, they found arresting parallels between how the monkeys represented images and how the computers did. \u201cThe paper was a game-changer,\u201d says Nancy Kanwisher, another professor at MIT who has spent much of her career studying the human visual system, and who now uses ANNs in some of her research. \u201cThe [artificial] network was not in any way designed to fit the brain. It was just designed to solve the problem and yet we see this incredible fit.\u201d\nSince then, whenever an ANN model has close to human performance on a task, neuroscientists have been eager to compare it with natural brains. They have found similarities between ANNs trained to recognise speech and process language, such as those used in transcription software, and the human auditory cortex. \nThe pattern holds for written language too. One paper published in 2021 compared human brain activity against many different commercial language models. It found that the most sophisticated ANN\u2014at the time OpenAI\u2019s GPT-2\u2014was the closest match for human brain activity. The better models get at solving certain tasks, the more similar they seem to get to the human brain doing the same.\nAnother indication that the analogy between artificial neural networks and natural ones is useful is that the study of the former can make testable predictions about the latter. A paper published in 2022, by researchers at Columbia University and MIT, found that an ANN trained on image-recognition tasks produced a group of artificial neurons devoted to classifying foodstuffs specifically. When the paper was published there was, as far as anyone knew, no analogous area of the human visual system. But the following year researchers from the same laboratory announced that they had discovered a region of the human brain that does indeed contain neurons that fire more often when a person is shown pictures of food.\nPerhaps the strongest evidence for the claim that artificial brains can reveal useful things about biological ones is the apparent ability for software and wetware to interact with each other directly. Nicholas Sexton and Bradley Love, a pair of neuroscientists of University College London, started out rather sceptical about the supposed resemblance between natural and artificial neural networks. Simply seeing similar patterns of activity, they argued, was not enough to claim that ANNs and brains were solving problems in the same way. To prove that the correspondence was meaningful, they suggested investigating whether it was possible to feed brain activity into an ANN.\nIn 2022 they published a paper in Science Advances that did just that. The researchers fed an ANN trained to recognise images data recorded by an MRI scanner examining human brains. The idea was to try to let the ANN \u201csee\u201d through human eyes. Sure enough, the hotwired ANN was able to interpret data from any of the hierarchical layers of the biological visual system\u2014though it did best with data from the higher levels, which had already been partly processed by the brain in question. If the computer model was shown brain activity from a human that was looking at a picture of a greyhound, for example, then it would say that it was looking at a greyhound\u2014as opposed to some other object\u2014almost 70% of the time. \nThe fact that a silicon brain can happily accept half-chewed data from a biological one suggests that, on some level, the two systems are performing the same sort of cognitive task. That insight might prove useful for brain-computer interfaces, which are devices that aim to allow biological brains to talk directly to machines. An ANN linked up to a camera, for instance, might be used to feed partly processed visual information into the brain. That might help treat some forms of blindness caused by damage to the brain\u2019s visual system. Several different research groups in Europe and America are already testing that idea in experiments on macaques.\nModels of the mind\nEven those most enthusiastic about ANNs do not argue they are perfect analogues of the human brain. Some make mistakes that humans never would\u2014give an ANN a picture of a cat but with the skin of an elephant, for example, and the model is more likely to identify it as an elephant. But no scientific model is ever perfect. The question is whether it is useful. One of neuroscience\u2019s problems is that experiments are difficult to run, for both ethical and practical reasons. Poking and prodding ANNs could offer a useful alternative. \nIn any case, comparing biology and silicon continues to produce intriguing results. In a paper published in May researchers from the University of Texas at Austin used a neural network to monitor brain signals from participants in an MRI scanner. Using just data from the mri, the ANN could produce a rough summary of a story that the test subject was listening to, a description of a film they were watching, or the gist of a sentence they were imagining. \u201cWhen I was in graduate school I would dream about something like this existing,\u201d says Dr Love. \u201cI thought it would be hundreds of years until we had something that works this well.\u201d  \u25a0\nCurious about the world? To enjoy our mind-expanding science coverage, sign up to Simply Science, our weekly subscriber-only newsletter.", "description": "No model is perfect. But that doesn\u2019t stop them being useful", "ogDescription": "No model is perfect. But that doesn\u2019t stop them being useful", "imageUrl": "https://www.economist.com/media-assets/image/20230527_STD001.jpg", "imageHeight": 720, "imageWidth": 1280, "datePublished": "2023-05-24T17:33:19Z", "dateModified": "2023-05-25T13:11:23Z", "dateCreated": "2023-05-24T10:31:12Z", "isPrintArticle": true, "printEdition": "2023-05-27T00:00:00Z", "copyrightYear": 2023, "dateline": "", "inLanguage": "en", "interactive": false, "scripts": [], "css": []}, "sectionArticles": [{"id": "/content/rqdi7uqpemsbnl5f26iq1cqfnmuvde60", "publication": [{"id": "/content/0ahcf9cn8l22qr8nr6rfn2sqtc5d9h59", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/134udl9j50scig3q9m2516gr6q75r5mr", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/s413ogt6tm4l7t13gh0psj7t0ov54lno", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/r148cgbtpn8r95kap4kb814ldbbofc2c", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/a9saae6o0e109j8560qfqj82kogau71b", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/o04190oq39a9tue8vjis18ius96kn1mk", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/23ni04hsk3d1ahu1j20tqnjho7tfj36o", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/050fcck58a4kilbnqmp37mdbrsnsiup8", "context": {"position": 1700.61, "__typename": "Content"}, "__typename": "Content"}], "headline": "Why Venetians are pondering raising their entire city", "url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/why-venetians-are-pondering-raising-their-entire-city", "__typename": "URL"}, "__typename": "Content"}, {"id": "/content/s70jg56mccbk8pqgigooqsqi96l4v78f", "publication": [{"id": "/content/0ahcf9cn8l22qr8nr6rfn2sqtc5d9h59", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/134udl9j50scig3q9m2516gr6q75r5mr", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/s413ogt6tm4l7t13gh0psj7t0ov54lno", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/r148cgbtpn8r95kap4kb814ldbbofc2c", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/a9saae6o0e109j8560qfqj82kogau71b", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/o04190oq39a9tue8vjis18ius96kn1mk", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/23ni04hsk3d1ahu1j20tqnjho7tfj36o", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/050fcck58a4kilbnqmp37mdbrsnsiup8", "context": {"position": 1700.58, "__typename": "Content"}, "__typename": "Content"}], "headline": "Artificial brains are helping scientists study the real thing", "url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/artificial-brains-are-helping-scientists-study-the-real-thing", "__typename": "URL"}, "__typename": "Content"}, {"id": "/content/p6d5p86paclflfempmm5s5ven42bkaig", "publication": [{"id": "/content/0ahcf9cn8l22qr8nr6rfn2sqtc5d9h59", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/134udl9j50scig3q9m2516gr6q75r5mr", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/s413ogt6tm4l7t13gh0psj7t0ov54lno", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/r148cgbtpn8r95kap4kb814ldbbofc2c", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/a9saae6o0e109j8560qfqj82kogau71b", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/o04190oq39a9tue8vjis18ius96kn1mk", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/23ni04hsk3d1ahu1j20tqnjho7tfj36o", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/050fcck58a4kilbnqmp37mdbrsnsiup8", "context": {"position": 1700.59, "__typename": "Content"}, "__typename": "Content"}], "headline": "Old tyres can become a climate-friendly fuel", "url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/old-tyres-can-become-a-climate-friendly-fuel", "__typename": "URL"}, "__typename": "Content"}, {"id": "/content/1qos3jsl1r3g3egdarpnvk54r6hghiq3", "publication": [{"id": "/content/0ahcf9cn8l22qr8nr6rfn2sqtc5d9h59", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/134udl9j50scig3q9m2516gr6q75r5mr", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/s413ogt6tm4l7t13gh0psj7t0ov54lno", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/r148cgbtpn8r95kap4kb814ldbbofc2c", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/a9saae6o0e109j8560qfqj82kogau71b", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/o04190oq39a9tue8vjis18ius96kn1mk", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/23ni04hsk3d1ahu1j20tqnjho7tfj36o", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/050fcck58a4kilbnqmp37mdbrsnsiup8", "context": {"position": 1700.6, "__typename": "Content"}, "__typename": "Content"}], "headline": "Parenting can be bad for the kids", "url": {"canonical": "https://www.economist.com/science-and-technology/2023/05/24/parenting-can-be-bad-for-the-kids", "__typename": "URL"}, "__typename": "Content"}]}