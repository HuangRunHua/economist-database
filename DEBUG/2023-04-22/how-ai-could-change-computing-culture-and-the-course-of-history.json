{"url": {"canonical": "https://www.economist.com/essay/2023/04/20/how-ai-could-change-computing-culture-and-the-course-of-history", "__typename": "URL"}, "__typename": "Content", "id": "/content/re6vv2c3kp32g0823hf6hmtqli1qnvas", "tegID": "re6vv2c3kp32g0823hf6hmtqli1qnvas", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "How AI could change computing, culture and the course of history", "subheadline": "Browsers, the printing press, Freud and AI", "seoPageTitle": null, "seoMetadataDescription": null, "ad": {"grapeshot": {"channels": [{"name": "gv_safe", "score": 15659.355, "__typename": "GrapeshotChannel"}, {"name": "gt_mixed", "score": 4.031, "__typename": "GrapeshotChannel"}, {"name": "future_of_work_test", "score": 3.864, "__typename": "GrapeshotChannel"}, {"name": "ts_tech", "score": 2.567, "__typename": "GrapeshotChannel"}, {"name": "ibm_cloud", "score": 2.517, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_computing", "score": 2.422, "__typename": "GrapeshotChannel"}, {"name": "gs_tech", "score": 1.925, "__typename": "GrapeshotChannel"}, {"name": "ibm_blacklist", "score": 1.838, "__typename": "GrapeshotChannel"}, {"name": "neg_omd_exclusion", "score": 1.744, "__typename": "GrapeshotChannel"}, {"name": "chanel_neg", "score": 1.529, "__typename": "GrapeshotChannel"}, {"name": "neg_3166_vca_brand-safety", "score": 1.482, "__typename": "GrapeshotChannel"}, {"name": "custom_punkt", "score": 1.473, "__typename": "GrapeshotChannel"}, {"name": "cigna_healthyhybridworkplace", "score": 1.37, "__typename": "GrapeshotChannel"}, {"name": "gs_science", "score": 1.332, "__typename": "GrapeshotChannel"}, {"name": "ge_tech_enthusiasts", "score": 1.317, "__typename": "GrapeshotChannel"}, {"name": "gs_busfin_business", "score": 1.312, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_compute", "score": 1.23, "__typename": "GrapeshotChannel"}, {"name": "neg_facebook", "score": 1.226, "__typename": "GrapeshotChannel"}, {"name": "gs_science_misc", "score": 1.191, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_compute_net", "score": 1.128, "__typename": "GrapeshotChannel"}, {"name": "gt_positive_curiosity", "score": 1.105, "__typename": "GrapeshotChannel"}, {"name": "neg_3166_vca_brand-safety3", "score": 1.078, "__typename": "GrapeshotChannel"}, {"name": "culture", "score": 1.071, "__typename": "GrapeshotChannel"}, {"name": "neg_dit4", "score": 1.071, "__typename": "GrapeshotChannel"}, {"name": "business_it_decisionmakers", "score": 1.022, "__typename": "GrapeshotChannel"}, {"name": "gt_negative_fear", "score": 0.998, "__typename": "GrapeshotChannel"}, {"name": "progressivemedia", "score": 0.974, "__typename": "GrapeshotChannel"}, {"name": "gs_busfin_business_startups", "score": 0.871, "__typename": "GrapeshotChannel"}, {"name": "gs_books", "score": 0.86, "__typename": "GrapeshotChannel"}, {"name": "gs_entertain_books", "score": 0.86, "__typename": "GrapeshotChannel"}, {"name": "neg_dit", "score": 0.835, "__typename": "GrapeshotChannel"}, {"name": "it_decisionmakers", "score": 0.823, "__typename": "GrapeshotChannel"}, {"name": "gs_tech_compute_apps", "score": 0.819, "__typename": "GrapeshotChannel"}, {"name": "test_mba", "score": 0.815, "__typename": "GrapeshotChannel"}, {"name": "artificial_intelligence", "score": 0.801, "__typename": "GrapeshotChannel"}, {"name": "fidelity_blacklist", "score": 0.783, "__typename": "GrapeshotChannel"}, {"name": "neg_google_youtube_2020", "score": 0.766, "__typename": "GrapeshotChannel"}, {"name": "workdayblocklist", "score": 0.753, "__typename": "GrapeshotChannel"}, {"name": "it_professionals", "score": 0.748, "__typename": "GrapeshotChannel"}, {"name": "neg_morgan_stanley_2019_neg_keywords", "score": 0.738, "__typename": "GrapeshotChannel"}, {"name": "google_negative_keywords", "score": 0.734, "__typename": "GrapeshotChannel"}], "__typename": "Grapeshot"}, "__typename": "Ad"}, "audio": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/audio/013%20Essay%20-%20Artificial%20intelligences-f4a99b45410f0595e92c25e383ab933f.mp3", "__typename": "URL"}, "__typename": "Content"}, "__typename": "Media"}, "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_ESD001.jpg", "__typename": "URL"}, "__typename": "Content", "height": 720, "width": 1280, "description": ""}, "promo": null, "__typename": "Media"}, "description": "Expect changes in the way people access knowledge, relate to knowledge and think about themselves", "datePublished": "2023-04-20T10:57:02Z", "dateModified": "2023-04-20T18:50:57Z", "dateModifiedString": "Apr 20th 2023", "datePublishedString": "Apr 20th 2023", "dateCreated": "2023-04-19T14:49:25Z", "copyrightYear": 2023, "inLanguage": "en", "byline": "", "dateline": "BERKELEY AND BERLIN", "text": [{"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "span", "attribs": {"data-caps": "initial"}, "children": [{"data": "A", "type": "text"}]}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "mong the", "type": "text"}]}, {"data": " more sombre gifts brought by the Enlightenment was the realisation that humans might one day become extinct. The astronomical revolution of the 17th century had shown that the solar system both operated according to the highest principles of reason and contained comets which might conceivably hit the Earth. The geological record, as interpreted by the Comte de Buffon, showed massive extinctions in which species vanished for ever. That set the scene for Charles Darwin to recognise such extinctions as the motor of evolution, and thus as both the force which had fashioned humans and, by implication, their possible destiny. The nascent science of thermodynamics added a cosmic dimension to the certainty of an ending; Sun, Earth and the whole shebang would eventually run down into a lifeless \u201cheat death\u201d. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The 20th century added the idea that extinction might not come about naturally, but through artifice. The spur for this was the discovery, and later exploitation, of the power locked up in atomic nuclei. Celebrated by some of its discoverers as a way of indefinitely deferring heat death, nuclear energy was soon developed into a far more proximate danger. And the tangible threat of imminent catastrophe which it posed rubbed off on other technologies.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "None was more tainted than the computer. It may have been guilt by association: the computer played a vital role in the development of the nuclear arsenal. It may have been foreordained. The Enlightenment belief in rationality as humankind\u2019s highest achievement and Darwin\u2019s theory of evolution made the promise of superhuman rationality the possibility of evolutionary progress at humankind\u2019s expense.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Artificial intelligence has come to loom large in the thought of the small but fascinating, and much written about, coterie of academics which has devoted itself to the consideration of existential risk over the past couple of decades. Indeed, it often appeared to be at the core of their concerns. A world which contained entities which think better and act quicker than humans and their institutions, and which had interests that were not aligned with those of humankind, would be a dangerous place.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "It became common for people within and around the field to say that there was a \u201cnon-zero\u201d chance of the development of superhuman ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "s leading to human extinction. The remarkable boom in the capabilities of large language models (", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s), \u201cfoundational\u201d models and related forms of \u201cgenerative\u201d ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " has propelled these discussions of existential risk into the public imagination and the inboxes of ministers. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "cite", "attribs": {}, "children": [{"data": "A technology need not be world-ending to be world-changing", "type": "text"}]}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "As the special ", "type": "text"}, {"type": "tag", "name": "a", "attribs": {"href": "https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work"}, "children": [{"data": "Science section", "type": "text"}]}, {"data": " in this issue makes clear, the field\u2019s progress is precipitate and its promise immense. That brings clear and present ", "type": "text"}, {"type": "tag", "name": "a", "attribs": {"href": "https://www.economist.com/leaders/2023/04/20/how-to-worry-wisely-about-artificial-intelligence", "data-tegid": "4ct5r2etoctqg4eqe86ateetnpo4nje3"}, "children": [{"data": "dangers", "type": "text"}]}, {"data": " which need addressing. But in the specific context of ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT-4", "type": "text"}]}, {"data": ", the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM ", "type": "text"}]}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "du jour", "type": "text"}]}, {"data": ", and its generative ilk, talk of existential risks seems rather absurd. They produce prose, poetry and code; they generate images, sound and video; they make predictions based on patterns. It is easy to see that those capabilities bring with them a huge capacity for mischief. It is hard to imagine them underpinning \u201cthe power to control civilisation\u201d, or to \u201creplace us\u201d, as hyperbolic critics warn. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Love song", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "But the lack of any \u201cMinds that are to our minds as ours are to those of the beasts that perish, intellects vast and cool and unsympathetic [drawing] their plans against us\u201d, to quote H.G. Wells, does not mean that the scale of the changes that ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " may bring with it can be ignored or should be minimised. There is much more to life than the avoidance of extinction. A technology need not be world-ending to be world-changing. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The transition into a world filled with computer programs capable of human levels of conversation and language comprehension and superhuman powers of data assimilation and pattern recognition has just begun. The coming of ubiquitous pseudocognition along these lines could be a turning point in history even if the current pace of ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI ", "type": "text"}]}, {"data": "progress slackens (which it might) or fundamental developments have been tapped out (which feels unlikely). It can be expected to have implications not just for how people earn their livings and organise their lives, but also for how they think about their humanity. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "For a sense of what may be on the way, consider three possible analogues, or precursors: the browser, the printing press and practice of psychoanalysis. One changed computers and the economy, one changed how people gained access and related to knowledge, and one changed how people understood themselves. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The humble web browser, introduced in the early 1990s as a way to share files across networks, changed the ways in which computers are used, the way in which the computer industry works and the way information is organised. Combined with the ability to link computers into networks, the browser became a window through which first files and then applications could be accessed wherever they might be located. The interface through which a user interacted with an application was separated from the application itself. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The power of the browser was immediately obvious. Fights over how hard users could be pushed towards a particular browser became a matter of high commercial drama. Almost any business with a web address could get funding, no matter what absurdity it promised. When boom turned to bust at the turn of the century there was a predictable backlash. But the fundamental separation of interface and application continued. Amazon, Meta (", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "n\u00e9e ", "type": "text"}]}, {"data": "Facebook) and Alphabet (", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "n\u00e9e", "type": "text"}]}, {"data": " Google) rose to giddy heights by making the browser a conduit for goods, information and human connections. Who made the browsers became incidental; their role as a platform became fundamental.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The months since the release of Open", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "\u2019s Chat", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": ", a conversational interface now powered by ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT-4", "type": "text"}]}, {"data": ", have seen an entrepreneurial explosion that makes the dotcom boom look sedate. For users, apps based on ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s and similar software can be ludicrously easy to use; type a prompt and see a result. For developers it is not that much harder. \u201cYou can just open your laptop and write a few lines of code that interact with the model,\u201d explains Ben Tossell, a British entrepreneur who publishes a newsletter about ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI ", "type": "text"}]}, {"data": "services.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "And the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s are increasingly capable of helping with that coding, too. Having been \u201ctrained\u201d not just on reams of text, but lots of code, they contain the building blocks of many possible programs; that lets them act as \u201cco-pilots\u201d for coders. Programmers on GitHub, an open-source coding site, are now using a ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT-4", "type": "text"}]}, {"data": "-based co-pilot to produce nearly half their code. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "There is no reason why this ability should not eventually allow", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": " LLM", "type": "text"}]}, {"data": "s to put code together on the fly, explains Kevin Scott, Microsoft\u2019s chief technology officer. The capacity to translate from one language to another includes, in principle and increasingly in practice, the ability to translate from language to code. A prompt written in English can in principle spur the production of a program that fulfils its requirements. Where browsers detached the user interface from the software application, ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s are likely to dissolve both categories. This could mark a fundamental shift in both the way people use computers and the business models within which they do so. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Every day I write the book", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Code-as-a-service sounds like a game-changing plus. A similarly creative approach to accounts of the world is a minus. While browsers mainly provided a window on content and code produced by humans, ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s generate their content themselves. When doing so they \u201challucinate\u201d (or as some prefer \u201cconfabulate\u201d) in various ways. Some hallucinations are simply nonsense. Some, such as the incorporation of fictitious misdeeds to biographical sketches of living people, are both plausible and harmful. The hallucinations can be generated by contradictions in training sets and by ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s being designed to produce coherence rather than truth. They create things which look like things in their training sets; they have no sense of a world beyond the texts and images on which they are trained. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "In many applications a tendency to spout plausible lies is a bug. For some it may prove a feature. Deep fakes and fabricated videos which traduce politicians are only the beginning. Expect the models to be used to set up malicious influence networks on demand, complete with fake websites, Twitter bots, Facebook pages, TikTok feeds and much more. The supply of disinformation, Ren\u00e9e DiResta of the Stanford Internet Observatory has warned, \u201cwill soon be infinite\u201d.", "type": "text"}]}, {"type": "tag", "name": "figure", "attribs": {"itemtype": "https://schema.org/ImageObject"}, "children": [{"type": "tag", "name": "img", "attribs": {"src": "https://www.economist.com/media-assets/image/20230422_ESD002.jpg", "data-teg-id": "937n8sctt812902192phqtaqiu61lqvn", "height": "720", "width": "1280"}, "children": []}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "This threat to the very possibility of public debate may not be an existential one; but it is deeply troubling. It brings to mind the \u201cLibrary of Babel\u201d, a short story by Jorge Luis Borges. The library contains all the books that have ever been written, but also all the books which were never written, books that are wrong, books that are nonsense. Everything that matters is there, but it cannot be found because of everything else; the librarians are driven to madness and despair. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "This fantasy has an obvious technological substrate. It takes the printing press\u2019s ability to recombine a fixed set of symbols in an unlimited number of ways to its ultimate limit. And that provides another way of thinking about ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Dreams never end", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "The degree to which the modern world is unimaginable without printing makes any guidance its history might provide for speculation about ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s at best partial, at worst misleading. Johannes Gutenberg\u2019s development of movable type has been awarded responsibility, at some time or other, for almost every facet of life that grew up in the centuries which followed. It changed relations between God and man, man and woman, past and present. It allowed the mass distribution of opinions, the systematisation of bureaucracy, the accumulation of knowledge. It brought into being the notion of intellectual property and the possibility of its piracy. But that very breadth makes comparison almost unavoidable. As Bradford DeLong, an economic historian at the University of California, Berkeley puts it, \u201cIt\u2019s the one real thing we have in which the price of creating information falls by an order of magnitude.\u201d", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Printed books made it possible for scholars to roam larger fields of knowledge than had ever before been possible. In that there is an obvious analogy for ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s, which trained on a given corpus of knowledge can derive all manner of things from it. But there was more to the acquisition of books than mere knowledge. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Just over a century after Gutenberg\u2019s press began its clattering Michel de Montaigne, a French aristocrat, had been able to amass a personal library of some 1,500 books\u2014something unimaginable for an individual of any earlier European generation. The library gave him more than knowledge. It gave him friends. \u201cWhen I am attacked by gloomy thoughts,\u201d he wrote, \u201cnothing helps me so much as running to my books. They quickly absorb me and banish the clouds from my mind.\u201d ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "And the idea of the book gave him a way of being himself no one had previously explored: to put himself between covers. \u201cReader,\u201d he warned in the preface to his ", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": "Essays", "type": "text"}]}, {"data": ", \u201cI myself am the matter of my book.\u201d The mass production of books allowed them to become peculiarly personal; it was possible to write a book about nothing more, or less, than yourself, and the person that your reading of other books had made you. Books produced authors.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "As a way of presenting knowledge, ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s promise to take both the practical and personal side of books further, in some cases abolishing them altogether. An obvious application of the technology is to turn bodies of knowledge into subject matter for chatbots. Rather than reading a corpus of text, you will question an entity trained on it and get responses based on what the text says. Why turn pages when you can interrogate a work as a whole?", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Everyone and everything now seems to be pursuing such fine-tuned models as ways of providing access to knowledge. Bloomberg, a media company, is working on Bloomberg", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": ", a model for financial information. There are early versions of a Quran", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": " and a Bible", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": "; can a puffer-jacketed Pontiff", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "GPT", "type": "text"}]}, {"data": " be far behind? Meanwhile several startups are offering services that turn all the documents on a user\u2019s hard disk, or in their bit of the cloud, into a resource for conversational consultation. Many early adopters are already using chatbots as sounding boards. \u201cIt\u2019s like a knowledgeable colleague you can always talk to,\u201d explains Jack Clark of Anthropic, an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM-", "type": "text"}]}, {"data": "making startup. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "cite", "attribs": {}, "children": [{"data": "If some chatbots become their user\u2019s inner voice, that voice will persist after death", "type": "text"}]}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "It is easy to imagine such intermediaries having what would seem like personalities\u2014not just generic ones, such as \u201cavuncular tutor\u201d, but specific ones which grow with time. They might come to be like their users: an externalised version of their inner voice. Or they might be like any other person whose online output is sufficient for a model to train on (intellectual-property concerns permitting). Researchers at the Australian Institute for Machine Learning have built an early version of such an assistant for Laurie Anderson, a composer and musician. It is trained in part on her work, and in part on that of her late husband Lou Reed. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "Without you", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Ms Anderson says she does not consider using the system as a way of collaborating with her dead partner. Others might succumb more readily to such an illusion. If some chatbots do become, to some extent, their user\u2019s inner voice, then that voice will persist after death, should others wish to converse with it. That some people will leave chatbots of themselves behind when they die seems all but certain. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Such applications and implications call to mind Sigmund Freud\u2019s classic essay on the", "type": "text"}, {"type": "tag", "name": "i", "attribs": {}, "children": [{"data": " Unheimliche", "type": "text"}]}, {"data": ", or uncanny. Freud takes as his starting point the idea that uncanniness stems from \u201cdoubts [as to] whether an apparently animate being is really alive; or conversely, whether a lifeless object might not be in fact animate\u201d. They are the sort of doubts that those thinking about ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s are hard put to avoid.", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Though ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI ", "type": "text"}]}, {"data": "researchers can explain the mechanics of their creations, they are persistently unable to say what actually happens within them. \u201cThere\u2019s no \u2018ultimate theoretical reason\u2019 why anything like this should work,\u201d Stephen Wolfram, a computer scientist and the creator of Wolfram Alpha, a mathematical search engine, recently concluded in a remarkable (and lengthy) blog post trying to explain the models\u2019 inner workings. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "This raises two linked but mutually exclusive concerns: that ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "\u2019s have some sort of internal working which scientists cannot yet perceive; or that it is possible to pass as human in the social world without any sort of inner understanding. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "\u201cThese models are just representations of the distributions of words in texts that can be used to produce more words,\u201d says Emily Bender, a professor at the University of Washington in Seattle. She is one of the authors of \u201cOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\u201d a critique of ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": " triumphalism. The models, she argues, have no real understanding. With no experience of real life or human communication they offer nothing more than the ability to parrot things they have heard in training, an ability which huge amounts of number crunching makes frequently appropriate and sometimes surprising, but which is nothing like thought. It is a view which is often pronounced in those who have come into the field through linguistics, as Dr Bender has. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "For some in the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "-building trade things are not that simple. Their models are hard to dismiss as \u201cmere babblers\u201d, in the words of Blaise Ag\u00fcera y Arcas, the leader of a group at Alphabet which works on ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "-powered products. He thinks the models have attributes which cannot really be distinguished from an ability to know what things actually mean. It can be seen, he suggests, in their ability reliably to choose the right meaning when translating phrases which are grammatically ambiguous, or to explain jokes. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "If Dr Bender is right, then it can be argued that a broad range of behaviour that humans have come to think of as essentially human is not necessarily so. Uncanny \u201cdoubts [as to] whether an apparently animate being is really alive\u201d are fully justified. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "To accept that human-seeming ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s are calculation, statistics and nothing more could influence how people think about themselves. Freud portrayed himself as continuing the trend begun by Copernicus\u2014who removed humans from the centre of the universe\u2014and Darwin\u2014who removed them from a special and God-given status among the animals. Psychology\u2019s contribution, as Freud saw it, lay in \u201cendeavouring to prove to the \u2018ego\u2019 of each one of us that he is not even master in his own house\u201d. ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s could be argued to take the idea further still. At least one wing of Freud\u2019s house becomes an unoccupied \u201csmart home\u201d; the lights go on and off automatically, the smart thermostat opens windows and lowers blinds, the roomba roombas around. No master needed at all. ", "type": "text"}]}, {"type": "tag", "name": "figure", "attribs": {"itemtype": "https://schema.org/ImageObject"}, "children": [{"type": "tag", "name": "img", "attribs": {"src": "https://www.economist.com/media-assets/image/20230422_ESD003.jpg", "data-teg-id": "cqr4svb67j80rpru3k16eusns2q6hscq", "height": "720", "width": "1280"}, "children": []}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Uncanny as that may all be, though, it would be wrong to think that many people will take this latest decentring to heart. As far as everyday life is concerned, humankind has proved pretty resilient to Copernicus, Darwin and Freud. People still believe in gods and souls and specialness with little obvious concern for countervailing science. They could well adapt quite easily to the pseudocognitive world, at least as far as philosophical qualms are concerned. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "You do not have to buy Freud\u2019s explanation of the unsettling effect of the uncanny in terms of the effort the mind expends on repressing childish animism to think that not worrying and going with the animistic flow will make a world populated with communicative pseudo-people a surprisingly comfortable one. People may simultaneously recognise that something is not alive and treat it as if it were. Some will take this too far, forming problematic attachments that Freud would have dubbed fetishistic. But only a few sensitive souls will find themselves left behind staring into an existential\u2014but personal\u2014abyss opened up by the possibility that their seeming thought is all for naught. ", "type": "text"}]}, {"type": "tag", "name": "h2", "attribs": {}, "children": [{"data": "New gold dream", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "What if Mr Ag\u00fcera y Arcas is right, though, and that which science deems lifeless is, in some cryptic, partial and emergent way, effectively animate? Then it will be time to do for ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " some of what Freud thought he was doing for humans. Having realised that the conscious mind was not the whole show, Freud looked elsewhere for sources of desire that for good or ill drove behaviour. Very few people now subscribe to the specific Freudian explanations of human behaviour which followed. But the idea that there are reasons why people do things of which they are not conscious is part of the world\u2019s mental furniture. The unconscious is probably not a great model for whatever it is that provides ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": "s with an apparent sense of meaning or an approximation of agency. But the sense that there might be something below the ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI ", "type": "text"}]}, {"data": "surface which needs understanding may prove powerful. ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "cite", "attribs": {}, "children": [{"data": "There might be something below the AI", "type": "text"}, {"data": " surface which needs understanding", "type": "text"}]}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "Dr Bender and those who agree with her may take issue with such notions. But they might find that they lead to useful actions in the field of \u201c", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " ethics\u201d. Winkling out non-conscious biases acquired in the pre-verbal infancy of training; dealing with the contradictions behind hallucinations; regularising rogue desires: ideas from psychotherapy might be seen as helpful analogies for dealing with the pseudocognitive ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " transition even by those who reject all notion of an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": " mind. A concentration on the relationship between parents, or programmers, and their children could be welcome, too. What is it to bring up an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI ", "type": "text"}]}, {"data": "well? What sort of upbringing should be forbidden? To what extent should the creators of ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "AI", "type": "text"}]}, {"data": "s be held responsible for the harms done by their creation? ", "type": "text"}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"data": "And human desires may need some inspection, too. Why are so many people eager for the sort of intimacy an ", "type": "text"}, {"type": "tag", "name": "small", "attribs": {}, "children": [{"data": "LLM", "type": "text"}]}, {"data": " might provide? Why do many influential humans seem to think that, because evolution shows species can go extinct, theirs is quite likely to do so at its own hand, or that of its successor? And where is the determination to turn a superhuman rationality into something which does not merely stir up the economy, but changes history for the better?", "type": "text"}, {"type": "tag", "name": "span", "attribs": {"data-ornament": "ufinish"}, "children": [{"data": "\u25a0", "type": "text"}]}]}, {"type": "tag", "name": "p", "attribs": {}, "children": [{"type": "tag", "name": "br", "attribs": {}, "children": []}]}], "bodyText": "Among the more sombre gifts brought by the Enlightenment was the realisation that humans might one day become extinct. The astronomical revolution of the 17th century had shown that the solar system both operated according to the highest principles of reason and contained comets which might conceivably hit the Earth. The geological record, as interpreted by the Comte de Buffon, showed massive extinctions in which species vanished for ever. That set the scene for Charles Darwin to recognise such extinctions as the motor of evolution, and thus as both the force which had fashioned humans and, by implication, their possible destiny. The nascent science of thermodynamics added a cosmic dimension to the certainty of an ending; Sun, Earth and the whole shebang would eventually run down into a lifeless \u201cheat death\u201d. \nThe 20th century added the idea that extinction might not come about naturally, but through artifice. The spur for this was the discovery, and later exploitation, of the power locked up in atomic nuclei. Celebrated by some of its discoverers as a way of indefinitely deferring heat death, nuclear energy was soon developed into a far more proximate danger. And the tangible threat of imminent catastrophe which it posed rubbed off on other technologies.\nNone was more tainted than the computer. It may have been guilt by association: the computer played a vital role in the development of the nuclear arsenal. It may have been foreordained. The Enlightenment belief in rationality as humankind\u2019s highest achievement and Darwin\u2019s theory of evolution made the promise of superhuman rationality the possibility of evolutionary progress at humankind\u2019s expense.\nArtificial intelligence has come to loom large in the thought of the small but fascinating, and much written about, coterie of academics which has devoted itself to the consideration of existential risk over the past couple of decades. Indeed, it often appeared to be at the core of their concerns. A world which contained entities which think better and act quicker than humans and their institutions, and which had interests that were not aligned with those of humankind, would be a dangerous place.\nIt became common for people within and around the field to say that there was a \u201cnon-zero\u201d chance of the development of superhuman AIs leading to human extinction. The remarkable boom in the capabilities of large language models (LLMs), \u201cfoundational\u201d models and related forms of \u201cgenerative\u201d AI has propelled these discussions of existential risk into the public imagination and the inboxes of ministers. \nA technology need not be world-ending to be world-changingAs the special Science section in this issue makes clear, the field\u2019s progress is precipitate and its promise immense. That brings clear and present dangers which need addressing. But in the specific context of GPT-4, the LLM du jour, and its generative ilk, talk of existential risks seems rather absurd. They produce prose, poetry and code; they generate images, sound and video; they make predictions based on patterns. It is easy to see that those capabilities bring with them a huge capacity for mischief. It is hard to imagine them underpinning \u201cthe power to control civilisation\u201d, or to \u201creplace us\u201d, as hyperbolic critics warn. \nLove song\nBut the lack of any \u201cMinds that are to our minds as ours are to those of the beasts that perish, intellects vast and cool and unsympathetic [drawing] their plans against us\u201d, to quote H.G. Wells, does not mean that the scale of the changes that AI may bring with it can be ignored or should be minimised. There is much more to life than the avoidance of extinction. A technology need not be world-ending to be world-changing. \nThe transition into a world filled with computer programs capable of human levels of conversation and language comprehension and superhuman powers of data assimilation and pattern recognition has just begun. The coming of ubiquitous pseudocognition along these lines could be a turning point in history even if the current pace of AI progress slackens (which it might) or fundamental developments have been tapped out (which feels unlikely). It can be expected to have implications not just for how people earn their livings and organise their lives, but also for how they think about their humanity. \nFor a sense of what may be on the way, consider three possible analogues, or precursors: the browser, the printing press and practice of psychoanalysis. One changed computers and the economy, one changed how people gained access and related to knowledge, and one changed how people understood themselves. \nThe humble web browser, introduced in the early 1990s as a way to share files across networks, changed the ways in which computers are used, the way in which the computer industry works and the way information is organised. Combined with the ability to link computers into networks, the browser became a window through which first files and then applications could be accessed wherever they might be located. The interface through which a user interacted with an application was separated from the application itself. \nThe power of the browser was immediately obvious. Fights over how hard users could be pushed towards a particular browser became a matter of high commercial drama. Almost any business with a web address could get funding, no matter what absurdity it promised. When boom turned to bust at the turn of the century there was a predictable backlash. But the fundamental separation of interface and application continued. Amazon, Meta (n\u00e9e Facebook) and Alphabet (n\u00e9e Google) rose to giddy heights by making the browser a conduit for goods, information and human connections. Who made the browsers became incidental; their role as a platform became fundamental.\nThe months since the release of OpenAI\u2019s ChatGPT, a conversational interface now powered by GPT-4, have seen an entrepreneurial explosion that makes the dotcom boom look sedate. For users, apps based on LLMs and similar software can be ludicrously easy to use; type a prompt and see a result. For developers it is not that much harder. \u201cYou can just open your laptop and write a few lines of code that interact with the model,\u201d explains Ben Tossell, a British entrepreneur who publishes a newsletter about AI services.\nAnd the LLMs are increasingly capable of helping with that coding, too. Having been \u201ctrained\u201d not just on reams of text, but lots of code, they contain the building blocks of many possible programs; that lets them act as \u201cco-pilots\u201d for coders. Programmers on GitHub, an open-source coding site, are now using a GPT-4-based co-pilot to produce nearly half their code. \nThere is no reason why this ability should not eventually allow LLMs to put code together on the fly, explains Kevin Scott, Microsoft\u2019s chief technology officer. The capacity to translate from one language to another includes, in principle and increasingly in practice, the ability to translate from language to code. A prompt written in English can in principle spur the production of a program that fulfils its requirements. Where browsers detached the user interface from the software application, LLMs are likely to dissolve both categories. This could mark a fundamental shift in both the way people use computers and the business models within which they do so. \nEvery day I write the book\nCode-as-a-service sounds like a game-changing plus. A similarly creative approach to accounts of the world is a minus. While browsers mainly provided a window on content and code produced by humans, LLMs generate their content themselves. When doing so they \u201challucinate\u201d (or as some prefer \u201cconfabulate\u201d) in various ways. Some hallucinations are simply nonsense. Some, such as the incorporation of fictitious misdeeds to biographical sketches of living people, are both plausible and harmful. The hallucinations can be generated by contradictions in training sets and by LLMs being designed to produce coherence rather than truth. They create things which look like things in their training sets; they have no sense of a world beyond the texts and images on which they are trained. \nIn many applications a tendency to spout plausible lies is a bug. For some it may prove a feature. Deep fakes and fabricated videos which traduce politicians are only the beginning. Expect the models to be used to set up malicious influence networks on demand, complete with fake websites, Twitter bots, Facebook pages, TikTok feeds and much more. The supply of disinformation, Ren\u00e9e DiResta of the Stanford Internet Observatory has warned, \u201cwill soon be infinite\u201d.\n\nThis threat to the very possibility of public debate may not be an existential one; but it is deeply troubling. It brings to mind the \u201cLibrary of Babel\u201d, a short story by Jorge Luis Borges. The library contains all the books that have ever been written, but also all the books which were never written, books that are wrong, books that are nonsense. Everything that matters is there, but it cannot be found because of everything else; the librarians are driven to madness and despair. \nThis fantasy has an obvious technological substrate. It takes the printing press\u2019s ability to recombine a fixed set of symbols in an unlimited number of ways to its ultimate limit. And that provides another way of thinking about LLMs. \nDreams never end\nThe degree to which the modern world is unimaginable without printing makes any guidance its history might provide for speculation about LLMs at best partial, at worst misleading. Johannes Gutenberg\u2019s development of movable type has been awarded responsibility, at some time or other, for almost every facet of life that grew up in the centuries which followed. It changed relations between God and man, man and woman, past and present. It allowed the mass distribution of opinions, the systematisation of bureaucracy, the accumulation of knowledge. It brought into being the notion of intellectual property and the possibility of its piracy. But that very breadth makes comparison almost unavoidable. As Bradford DeLong, an economic historian at the University of California, Berkeley puts it, \u201cIt\u2019s the one real thing we have in which the price of creating information falls by an order of magnitude.\u201d\nPrinted books made it possible for scholars to roam larger fields of knowledge than had ever before been possible. In that there is an obvious analogy for LLMs, which trained on a given corpus of knowledge can derive all manner of things from it. But there was more to the acquisition of books than mere knowledge. \nJust over a century after Gutenberg\u2019s press began its clattering Michel de Montaigne, a French aristocrat, had been able to amass a personal library of some 1,500 books\u2014something unimaginable for an individual of any earlier European generation. The library gave him more than knowledge. It gave him friends. \u201cWhen I am attacked by gloomy thoughts,\u201d he wrote, \u201cnothing helps me so much as running to my books. They quickly absorb me and banish the clouds from my mind.\u201d \nAnd the idea of the book gave him a way of being himself no one had previously explored: to put himself between covers. \u201cReader,\u201d he warned in the preface to his Essays, \u201cI myself am the matter of my book.\u201d The mass production of books allowed them to become peculiarly personal; it was possible to write a book about nothing more, or less, than yourself, and the person that your reading of other books had made you. Books produced authors.\nAs a way of presenting knowledge, LLMs promise to take both the practical and personal side of books further, in some cases abolishing them altogether. An obvious application of the technology is to turn bodies of knowledge into subject matter for chatbots. Rather than reading a corpus of text, you will question an entity trained on it and get responses based on what the text says. Why turn pages when you can interrogate a work as a whole?\nEveryone and everything now seems to be pursuing such fine-tuned models as ways of providing access to knowledge. Bloomberg, a media company, is working on BloombergGPT, a model for financial information. There are early versions of a QuranGPT and a BibleGPT; can a puffer-jacketed PontiffGPT be far behind? Meanwhile several startups are offering services that turn all the documents on a user\u2019s hard disk, or in their bit of the cloud, into a resource for conversational consultation. Many early adopters are already using chatbots as sounding boards. \u201cIt\u2019s like a knowledgeable colleague you can always talk to,\u201d explains Jack Clark of Anthropic, an LLM-making startup. \nIf some chatbots become their user\u2019s inner voice, that voice will persist after deathIt is easy to imagine such intermediaries having what would seem like personalities\u2014not just generic ones, such as \u201cavuncular tutor\u201d, but specific ones which grow with time. They might come to be like their users: an externalised version of their inner voice. Or they might be like any other person whose online output is sufficient for a model to train on (intellectual-property concerns permitting). Researchers at the Australian Institute for Machine Learning have built an early version of such an assistant for Laurie Anderson, a composer and musician. It is trained in part on her work, and in part on that of her late husband Lou Reed. \nWithout you\nMs Anderson says she does not consider using the system as a way of collaborating with her dead partner. Others might succumb more readily to such an illusion. If some chatbots do become, to some extent, their user\u2019s inner voice, then that voice will persist after death, should others wish to converse with it. That some people will leave chatbots of themselves behind when they die seems all but certain. \nSuch applications and implications call to mind Sigmund Freud\u2019s classic essay on the Unheimliche, or uncanny. Freud takes as his starting point the idea that uncanniness stems from \u201cdoubts [as to] whether an apparently animate being is really alive; or conversely, whether a lifeless object might not be in fact animate\u201d. They are the sort of doubts that those thinking about LLMs are hard put to avoid.\nThough AI researchers can explain the mechanics of their creations, they are persistently unable to say what actually happens within them. \u201cThere\u2019s no \u2018ultimate theoretical reason\u2019 why anything like this should work,\u201d Stephen Wolfram, a computer scientist and the creator of Wolfram Alpha, a mathematical search engine, recently concluded in a remarkable (and lengthy) blog post trying to explain the models\u2019 inner workings. \nThis raises two linked but mutually exclusive concerns: that AI\u2019s have some sort of internal working which scientists cannot yet perceive; or that it is possible to pass as human in the social world without any sort of inner understanding. \n\u201cThese models are just representations of the distributions of words in texts that can be used to produce more words,\u201d says Emily Bender, a professor at the University of Washington in Seattle. She is one of the authors of \u201cOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\u201d a critique of LLM triumphalism. The models, she argues, have no real understanding. With no experience of real life or human communication they offer nothing more than the ability to parrot things they have heard in training, an ability which huge amounts of number crunching makes frequently appropriate and sometimes surprising, but which is nothing like thought. It is a view which is often pronounced in those who have come into the field through linguistics, as Dr Bender has. \nFor some in the LLM-building trade things are not that simple. Their models are hard to dismiss as \u201cmere babblers\u201d, in the words of Blaise Ag\u00fcera y Arcas, the leader of a group at Alphabet which works on AI-powered products. He thinks the models have attributes which cannot really be distinguished from an ability to know what things actually mean. It can be seen, he suggests, in their ability reliably to choose the right meaning when translating phrases which are grammatically ambiguous, or to explain jokes. \nIf Dr Bender is right, then it can be argued that a broad range of behaviour that humans have come to think of as essentially human is not necessarily so. Uncanny \u201cdoubts [as to] whether an apparently animate being is really alive\u201d are fully justified. \nTo accept that human-seeming LLMs are calculation, statistics and nothing more could influence how people think about themselves. Freud portrayed himself as continuing the trend begun by Copernicus\u2014who removed humans from the centre of the universe\u2014and Darwin\u2014who removed them from a special and God-given status among the animals. Psychology\u2019s contribution, as Freud saw it, lay in \u201cendeavouring to prove to the \u2018ego\u2019 of each one of us that he is not even master in his own house\u201d. LLMs could be argued to take the idea further still. At least one wing of Freud\u2019s house becomes an unoccupied \u201csmart home\u201d; the lights go on and off automatically, the smart thermostat opens windows and lowers blinds, the roomba roombas around. No master needed at all. \n\nUncanny as that may all be, though, it would be wrong to think that many people will take this latest decentring to heart. As far as everyday life is concerned, humankind has proved pretty resilient to Copernicus, Darwin and Freud. People still believe in gods and souls and specialness with little obvious concern for countervailing science. They could well adapt quite easily to the pseudocognitive world, at least as far as philosophical qualms are concerned. \nYou do not have to buy Freud\u2019s explanation of the unsettling effect of the uncanny in terms of the effort the mind expends on repressing childish animism to think that not worrying and going with the animistic flow will make a world populated with communicative pseudo-people a surprisingly comfortable one. People may simultaneously recognise that something is not alive and treat it as if it were. Some will take this too far, forming problematic attachments that Freud would have dubbed fetishistic. But only a few sensitive souls will find themselves left behind staring into an existential\u2014but personal\u2014abyss opened up by the possibility that their seeming thought is all for naught. \nNew gold dream\nWhat if Mr Ag\u00fcera y Arcas is right, though, and that which science deems lifeless is, in some cryptic, partial and emergent way, effectively animate? Then it will be time to do for AI some of what Freud thought he was doing for humans. Having realised that the conscious mind was not the whole show, Freud looked elsewhere for sources of desire that for good or ill drove behaviour. Very few people now subscribe to the specific Freudian explanations of human behaviour which followed. But the idea that there are reasons why people do things of which they are not conscious is part of the world\u2019s mental furniture. The unconscious is probably not a great model for whatever it is that provides LLMs with an apparent sense of meaning or an approximation of agency. But the sense that there might be something below the AI surface which needs understanding may prove powerful. \nThere might be something below the AI surface which needs understandingDr Bender and those who agree with her may take issue with such notions. But they might find that they lead to useful actions in the field of \u201cAI ethics\u201d. Winkling out non-conscious biases acquired in the pre-verbal infancy of training; dealing with the contradictions behind hallucinations; regularising rogue desires: ideas from psychotherapy might be seen as helpful analogies for dealing with the pseudocognitive AI transition even by those who reject all notion of an AI mind. A concentration on the relationship between parents, or programmers, and their children could be welcome, too. What is it to bring up an AI well? What sort of upbringing should be forbidden? To what extent should the creators of AIs be held responsible for the harms done by their creation? \nAnd human desires may need some inspection, too. Why are so many people eager for the sort of intimacy an LLM might provide? Why do many influential humans seem to think that, because evolution shows species can go extinct, theirs is quite likely to do so at its own hand, or that of its successor? And where is the determination to turn a  superhuman rationality into something which does not merely stir up the economy, but changes history for the better?\u25a0", "about": {"public": null, "__typename": "Taxonomies"}, "print": {"headline": "THE AGE OF PSEUDOCOGNITION", "section": {"url": {"canonical": "https://www.economist.com/essay/", "__typename": "URL"}, "__typename": "Content", "headline": "Essay"}, "__typename": "Print"}, "articleSection": {"public": null, "internal": [{"url": {"canonical": "https://www.economist.com/essay/", "__typename": "URL"}, "__typename": "Content", "id": "/content/q55pqh5k2llslpqke73fmppmmjjgrrue", "tegID": "q55pqh5k2llslpqke73fmppmmjjgrrue", "headline": "Essay", "hasPart": {"parts": [{"url": {"canonical": "https://www.economist.com/essay/2023/04/20/how-ai-could-change-computing-culture-and-the-course-of-history", "__typename": "URL"}, "__typename": "Content", "id": "/content/re6vv2c3kp32g0823hf6hmtqli1qnvas", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "How AI could change computing, culture and the course of history", "subheadline": "Browsers, the printing press, Freud and AI", "datePublished": "2023-04-20T10:57:02Z", "description": "Expect changes in the way people access knowledge, relate to knowledge and think about themselves", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_ESD001.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/essay/2022/09/08/the-alaskan-wilderness-reveals-the-past-and-the-future", "__typename": "URL"}, "__typename": "Content", "id": "/content/3bkm1q6pq8sgmq254t3r5rj1hm5pkk8g", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "The Alaskan wilderness reveals the past and the future", "subheadline": "The view from a tent in the Arctic", "datePublished": "2022-09-08T18:41:35Z", "description": "The oil flows more slowly, the climate changes more quickly", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20220910_ESP030.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/interactive/essay/2022/07/01/how-hong-kong-became-a-police-state", "__typename": "URL"}, "__typename": "Content", "id": "/content/320s1thu4hc7obb6m3u1fvajjv81ku0t", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "How a free and open Hong Kong became a police state", "subheadline": "An anatomy of erasure", "datePublished": "2022-06-30T20:07:18Z", "description": "It was a long time in the planning", "image": {"main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20220709_ESD001.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": {"url": {"canonical": "https://www.economist.com/media-assets/image/20220709_ESD001.jpg", "__typename": "URL"}, "__typename": "Content", "height": 720, "width": 1280}}}, {"url": {"canonical": "https://www.economist.com/essay/2020/08/20/viruses-have-big-impacts-on-ecology-and-evolution-as-well-as-human-health", "__typename": "URL"}, "__typename": "Content", "id": "/content/4385ifdm1ob80m6jplmtr779qmbu5vqb", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "Viruses have big impacts on ecology and evolution as well as human health", "subheadline": "The viral universe", "datePublished": "2020-08-20T00:00:00Z", "description": "They are ubiquitous, diverse and very powerful", "image": {"main": {"url": {"canonical": "https://www.economist.com/sites/default/files/images/print-edition/20200822_ESD001_0.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}, {"url": {"canonical": "https://www.economist.com/essay/2019/06/27/the-south-asian-monsoon-past-present-and-future", "__typename": "URL"}, "__typename": "Content", "id": "/content/pdutadl6fsg0rtl7tcep7io0d76rvfpi", "type": ["Article", "NewsArticle", "AnalysisNewsArticle"], "headline": "The South Asian monsoon, past, present and future", "subheadline": "A gamble on the rains", "datePublished": "2019-06-27T00:00:00Z", "description": "A story of famines and trade, science and cupidity", "image": {"main": {"url": {"canonical": "https://www.economist.com/sites/default/files/images/2019/06/articles/main/20190629_esp029.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 720}, "__typename": "Media", "promo": null}}], "__typename": "HasPart"}}], "__typename": "Taxonomies"}, "publication": [{"url": {"canonical": "https://www.economist.com/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/oq02trftu9mc92lsd5itom87ufgqp15q", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["AF", "AS", "AU", "BD", "BT", "BN", "KH", "CN", "CK", "FJ", "GU", "PF", "HK", "IN", "ID", "JP", "KI", "KP", "KR", "LA", "MO", "MY", "MV", "MH", "FM", "MN", "MM", "NR", "NP", "NC", "NZ", "PK", "PG", "PH", "PN", "SC", "SG", "SB", "LK", "TF", "TW", "TH", "TO", "TV", "VU", "VN", "IO", "CC", "TL", "HM", "NU", "NF", "MP", "PW", "WS", "CX", "TK", "WF"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["UK", "GB", "GG", "IM", "JE", "AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}, {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/eu/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/4scc4vva7odlr6m76otihrom34b2lu80", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/ap/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/fqi3r1ipeqmp3sn7rnquv7getubmh3v2", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["AF", "AS", "AU", "BD", "BT", "BN", "KH", "CN", "CK", "FJ", "GU", "PF", "HK", "IN", "ID", "JP", "KI", "KP", "KR", "LA", "MO", "MY", "MV", "MH", "FM", "MN", "MM", "NR", "NP", "NC", "NZ", "PK", "PG", "PH", "PN", "SC", "SG", "SB", "LK", "TF", "TW", "TH", "TO", "TV", "VU", "VN", "IO", "CC", "TL", "HM", "NU", "NF", "MP", "PW", "WS", "CX", "TK", "WF"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_AP.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/la/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/2q9c1n7p82uugfpdffl189mrkemql2f7", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/me/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/oebc7jcc10bin6t3e44svq590regi5bv", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/uk/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/qk3633vlq3r42orc70a3haatrqk3f45s", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["UK", "GB", "GG", "IM", "JE", "AD", "AL", "AM", "AX", "AZ", "BA", "BG", "BY", "CH", "CY", "CZ", "EE", "FO", "GE", "GI", "GL", "HR", "HU", "IS", "KG", "KZ", "LI", "LT", "LV", "MC", "MD", "ME", "MK", "MT", "NO", "PL", "RO", "RS", "RU", "SI", "SJ", "SK", "SM", "TJ", "TM", "TR", "UA", "UZ", "VA", "IT", "FR", "ES", "IE", "AT", "BE", "DK", "FI", "DE", "GR", "LU", "NL", "PT", "SE", "BH", "IR", "IQ", "IL", "JO", "KW", "LB", "OM", "SA", "SY", "AE", "PS", "QA", "YE", "DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MU", "MW", "ML", "MR", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "SH", "SS", "ST", "SN", "SL", "SO", "ZA", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW", "CG"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_UK.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}, {"url": {"canonical": "https://www.economist.com/na/printedition/2023-04-22", "__typename": "URL"}, "__typename": "Content", "type": ["PublicationIssue", "RegionalIssue"], "headline": "WEEKLY EDITION: APR 22ND 2023", "description": "", "subheadline": "", "datePublished": "2023-04-22T00:00:00Z", "datePublishedString": "Apr 22nd 2023", "id": "/content/588urv90n1p5co985p8os2oho9o1gj26", "image": {"cover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "headline": "How to worry wisely about AI", "width": 1280, "height": 1684, "regionsAllowed": ["US", "CA", "PM", "UM", "AI", "BL", "BQ", "BV", "CW", "GS", "MF", "SX", "AG", "AR", "AW", "BS", "BB", "BZ", "BM", "BO", "BR", "KY", "CL", "CO", "CR", "CU", "DM", "DO", "EC", "SV", "FK", "GF", "GD", "GP", "GT", "GY", "HN", "HT", "JM", "MQ", "MX", "MS", "NI", "PA", "PY", "PE", "PR", "KN", "LC", "VC", "SR", "TT", "TC", "UY", "VE", "VG", "VI"]}], "main": {"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1684}, "squareCover": [{"url": {"canonical": "https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg", "__typename": "URL"}, "__typename": "Content", "width": 1280, "height": 1280}], "__typename": "Media"}}], "channel": {"tegID": "j53t6hsedat4l7rkbb1le98u73262sh5", "__typename": "Content"}, "_metadata": {"articleId": "/content/re6vv2c3kp32g0823hf6hmtqli1qnvas", "tegID": "re6vv2c3kp32g0823hf6hmtqli1qnvas", "title": "Browsers, the printing press, Freud and AI - How AI could change computing, culture and the course of history | Essay | The Economist", "shareSnippet": "Browsers, the printing press, Freud and AI \u2013 How AI could change computing, culture and the course of history", "headline": "How AI could change computing, culture and the course of history", "section": "Essay", "keywords": [], "author": ["The Economist"], "url": "https://www.economist.com/essay/2023/04/20/how-ai-could-change-computing-culture-and-the-course-of-history", "type": "Article", "articleBody": "Among the more sombre gifts brought by the Enlightenment was the realisation that humans might one day become extinct. The astronomical revolution of the 17th century had shown that the solar system both operated according to the highest principles of reason and contained comets which might conceivably hit the Earth. The geological record, as interpreted by the Comte de Buffon, showed massive extinctions in which species vanished for ever. That set the scene for Charles Darwin to recognise such extinctions as the motor of evolution, and thus as both the force which had fashioned humans and, by implication, their possible destiny. The nascent science of thermodynamics added a cosmic dimension to the certainty of an ending; Sun, Earth and the whole shebang would eventually run down into a lifeless \u201cheat death\u201d. \nThe 20th century added the idea that extinction might not come about naturally, but through artifice. The spur for this was the discovery, and later exploitation, of the power locked up in atomic nuclei. Celebrated by some of its discoverers as a way of indefinitely deferring heat death, nuclear energy was soon developed into a far more proximate danger. And the tangible threat of imminent catastrophe which it posed rubbed off on other technologies.\nNone was more tainted than the computer. It may have been guilt by association: the computer played a vital role in the development of the nuclear arsenal. It may have been foreordained. The Enlightenment belief in rationality as humankind\u2019s highest achievement and Darwin\u2019s theory of evolution made the promise of superhuman rationality the possibility of evolutionary progress at humankind\u2019s expense.\nArtificial intelligence has come to loom large in the thought of the small but fascinating, and much written about, coterie of academics which has devoted itself to the consideration of existential risk over the past couple of decades. Indeed, it often appeared to be at the core of their concerns. A world which contained entities which think better and act quicker than humans and their institutions, and which had interests that were not aligned with those of humankind, would be a dangerous place.\nIt became common for people within and around the field to say that there was a \u201cnon-zero\u201d chance of the development of superhuman AIs leading to human extinction. The remarkable boom in the capabilities of large language models (LLMs), \u201cfoundational\u201d models and related forms of \u201cgenerative\u201d AI has propelled these discussions of existential risk into the public imagination and the inboxes of ministers. \nA technology need not be world-ending to be world-changingAs the special Science section in this issue makes clear, the field\u2019s progress is precipitate and its promise immense. That brings clear and present dangers which need addressing. But in the specific context of GPT-4, the LLM du jour, and its generative ilk, talk of existential risks seems rather absurd. They produce prose, poetry and code; they generate images, sound and video; they make predictions based on patterns. It is easy to see that those capabilities bring with them a huge capacity for mischief. It is hard to imagine them underpinning \u201cthe power to control civilisation\u201d, or to \u201creplace us\u201d, as hyperbolic critics warn. \nLove song\nBut the lack of any \u201cMinds that are to our minds as ours are to those of the beasts that perish, intellects vast and cool and unsympathetic [drawing] their plans against us\u201d, to quote H.G. Wells, does not mean that the scale of the changes that AI may bring with it can be ignored or should be minimised. There is much more to life than the avoidance of extinction. A technology need not be world-ending to be world-changing. \nThe transition into a world filled with computer programs capable of human levels of conversation and language comprehension and superhuman powers of data assimilation and pattern recognition has just begun. The coming of ubiquitous pseudocognition along these lines could be a turning point in history even if the current pace of AI progress slackens (which it might) or fundamental developments have been tapped out (which feels unlikely). It can be expected to have implications not just for how people earn their livings and organise their lives, but also for how they think about their humanity. \nFor a sense of what may be on the way, consider three possible analogues, or precursors: the browser, the printing press and practice of psychoanalysis. One changed computers and the economy, one changed how people gained access and related to knowledge, and one changed how people understood themselves. \nThe humble web browser, introduced in the early 1990s as a way to share files across networks, changed the ways in which computers are used, the way in which the computer industry works and the way information is organised. Combined with the ability to link computers into networks, the browser became a window through which first files and then applications could be accessed wherever they might be located. The interface through which a user interacted with an application was separated from the application itself. \nThe power of the browser was immediately obvious. Fights over how hard users could be pushed towards a particular browser became a matter of high commercial drama. Almost any business with a web address could get funding, no matter what absurdity it promised. When boom turned to bust at the turn of the century there was a predictable backlash. But the fundamental separation of interface and application continued. Amazon, Meta (n\u00e9e Facebook) and Alphabet (n\u00e9e Google) rose to giddy heights by making the browser a conduit for goods, information and human connections. Who made the browsers became incidental; their role as a platform became fundamental.\nThe months since the release of OpenAI\u2019s ChatGPT, a conversational interface now powered by GPT-4, have seen an entrepreneurial explosion that makes the dotcom boom look sedate. For users, apps based on LLMs and similar software can be ludicrously easy to use; type a prompt and see a result. For developers it is not that much harder. \u201cYou can just open your laptop and write a few lines of code that interact with the model,\u201d explains Ben Tossell, a British entrepreneur who publishes a newsletter about AI services.\nAnd the LLMs are increasingly capable of helping with that coding, too. Having been \u201ctrained\u201d not just on reams of text, but lots of code, they contain the building blocks of many possible programs; that lets them act as \u201cco-pilots\u201d for coders. Programmers on GitHub, an open-source coding site, are now using a GPT-4-based co-pilot to produce nearly half their code. \nThere is no reason why this ability should not eventually allow LLMs to put code together on the fly, explains Kevin Scott, Microsoft\u2019s chief technology officer. The capacity to translate from one language to another includes, in principle and increasingly in practice, the ability to translate from language to code. A prompt written in English can in principle spur the production of a program that fulfils its requirements. Where browsers detached the user interface from the software application, LLMs are likely to dissolve both categories. This could mark a fundamental shift in both the way people use computers and the business models within which they do so. \nEvery day I write the book\nCode-as-a-service sounds like a game-changing plus. A similarly creative approach to accounts of the world is a minus. While browsers mainly provided a window on content and code produced by humans, LLMs generate their content themselves. When doing so they \u201challucinate\u201d (or as some prefer \u201cconfabulate\u201d) in various ways. Some hallucinations are simply nonsense. Some, such as the incorporation of fictitious misdeeds to biographical sketches of living people, are both plausible and harmful. The hallucinations can be generated by contradictions in training sets and by LLMs being designed to produce coherence rather than truth. They create things which look like things in their training sets; they have no sense of a world beyond the texts and images on which they are trained. \nIn many applications a tendency to spout plausible lies is a bug. For some it may prove a feature. Deep fakes and fabricated videos which traduce politicians are only the beginning. Expect the models to be used to set up malicious influence networks on demand, complete with fake websites, Twitter bots, Facebook pages, TikTok feeds and much more. The supply of disinformation, Ren\u00e9e DiResta of the Stanford Internet Observatory has warned, \u201cwill soon be infinite\u201d.\n\nThis threat to the very possibility of public debate may not be an existential one; but it is deeply troubling. It brings to mind the \u201cLibrary of Babel\u201d, a short story by Jorge Luis Borges. The library contains all the books that have ever been written, but also all the books which were never written, books that are wrong, books that are nonsense. Everything that matters is there, but it cannot be found because of everything else; the librarians are driven to madness and despair. \nThis fantasy has an obvious technological substrate. It takes the printing press\u2019s ability to recombine a fixed set of symbols in an unlimited number of ways to its ultimate limit. And that provides another way of thinking about LLMs. \nDreams never end\nThe degree to which the modern world is unimaginable without printing makes any guidance its history might provide for speculation about LLMs at best partial, at worst misleading. Johannes Gutenberg\u2019s development of movable type has been awarded responsibility, at some time or other, for almost every facet of life that grew up in the centuries which followed. It changed relations between God and man, man and woman, past and present. It allowed the mass distribution of opinions, the systematisation of bureaucracy, the accumulation of knowledge. It brought into being the notion of intellectual property and the possibility of its piracy. But that very breadth makes comparison almost unavoidable. As Bradford DeLong, an economic historian at the University of California, Berkeley puts it, \u201cIt\u2019s the one real thing we have in which the price of creating information falls by an order of magnitude.\u201d\nPrinted books made it possible for scholars to roam larger fields of knowledge than had ever before been possible. In that there is an obvious analogy for LLMs, which trained on a given corpus of knowledge can derive all manner of things from it. But there was more to the acquisition of books than mere knowledge. \nJust over a century after Gutenberg\u2019s press began its clattering Michel de Montaigne, a French aristocrat, had been able to amass a personal library of some 1,500 books\u2014something unimaginable for an individual of any earlier European generation. The library gave him more than knowledge. It gave him friends. \u201cWhen I am attacked by gloomy thoughts,\u201d he wrote, \u201cnothing helps me so much as running to my books. They quickly absorb me and banish the clouds from my mind.\u201d \nAnd the idea of the book gave him a way of being himself no one had previously explored: to put himself between covers. \u201cReader,\u201d he warned in the preface to his Essays, \u201cI myself am the matter of my book.\u201d The mass production of books allowed them to become peculiarly personal; it was possible to write a book about nothing more, or less, than yourself, and the person that your reading of other books had made you. Books produced authors.\nAs a way of presenting knowledge, LLMs promise to take both the practical and personal side of books further, in some cases abolishing them altogether. An obvious application of the technology is to turn bodies of knowledge into subject matter for chatbots. Rather than reading a corpus of text, you will question an entity trained on it and get responses based on what the text says. Why turn pages when you can interrogate a work as a whole?\nEveryone and everything now seems to be pursuing such fine-tuned models as ways of providing access to knowledge. Bloomberg, a media company, is working on BloombergGPT, a model for financial information. There are early versions of a QuranGPT and a BibleGPT; can a puffer-jacketed PontiffGPT be far behind? Meanwhile several startups are offering services that turn all the documents on a user\u2019s hard disk, or in their bit of the cloud, into a resource for conversational consultation. Many early adopters are already using chatbots as sounding boards. \u201cIt\u2019s like a knowledgeable colleague you can always talk to,\u201d explains Jack Clark of Anthropic, an LLM-making startup. \nIf some chatbots become their user\u2019s inner voice, that voice will persist after deathIt is easy to imagine such intermediaries having what would seem like personalities\u2014not just generic ones, such as \u201cavuncular tutor\u201d, but specific ones which grow with time. They might come to be like their users: an externalised version of their inner voice. Or they might be like any other person whose online output is sufficient for a model to train on (intellectual-property concerns permitting). Researchers at the Australian Institute for Machine Learning have built an early version of such an assistant for Laurie Anderson, a composer and musician. It is trained in part on her work, and in part on that of her late husband Lou Reed. \nWithout you\nMs Anderson says she does not consider using the system as a way of collaborating with her dead partner. Others might succumb more readily to such an illusion. If some chatbots do become, to some extent, their user\u2019s inner voice, then that voice will persist after death, should others wish to converse with it. That some people will leave chatbots of themselves behind when they die seems all but certain. \nSuch applications and implications call to mind Sigmund Freud\u2019s classic essay on the Unheimliche, or uncanny. Freud takes as his starting point the idea that uncanniness stems from \u201cdoubts [as to] whether an apparently animate being is really alive; or conversely, whether a lifeless object might not be in fact animate\u201d. They are the sort of doubts that those thinking about LLMs are hard put to avoid.\nThough AI researchers can explain the mechanics of their creations, they are persistently unable to say what actually happens within them. \u201cThere\u2019s no \u2018ultimate theoretical reason\u2019 why anything like this should work,\u201d Stephen Wolfram, a computer scientist and the creator of Wolfram Alpha, a mathematical search engine, recently concluded in a remarkable (and lengthy) blog post trying to explain the models\u2019 inner workings. \nThis raises two linked but mutually exclusive concerns: that AI\u2019s have some sort of internal working which scientists cannot yet perceive; or that it is possible to pass as human in the social world without any sort of inner understanding. \n\u201cThese models are just representations of the distributions of words in texts that can be used to produce more words,\u201d says Emily Bender, a professor at the University of Washington in Seattle. She is one of the authors of \u201cOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\u201d a critique of LLM triumphalism. The models, she argues, have no real understanding. With no experience of real life or human communication they offer nothing more than the ability to parrot things they have heard in training, an ability which huge amounts of number crunching makes frequently appropriate and sometimes surprising, but which is nothing like thought. It is a view which is often pronounced in those who have come into the field through linguistics, as Dr Bender has. \nFor some in the LLM-building trade things are not that simple. Their models are hard to dismiss as \u201cmere babblers\u201d, in the words of Blaise Ag\u00fcera y Arcas, the leader of a group at Alphabet which works on AI-powered products. He thinks the models have attributes which cannot really be distinguished from an ability to know what things actually mean. It can be seen, he suggests, in their ability reliably to choose the right meaning when translating phrases which are grammatically ambiguous, or to explain jokes. \nIf Dr Bender is right, then it can be argued that a broad range of behaviour that humans have come to think of as essentially human is not necessarily so. Uncanny \u201cdoubts [as to] whether an apparently animate being is really alive\u201d are fully justified. \nTo accept that human-seeming LLMs are calculation, statistics and nothing more could influence how people think about themselves. Freud portrayed himself as continuing the trend begun by Copernicus\u2014who removed humans from the centre of the universe\u2014and Darwin\u2014who removed them from a special and God-given status among the animals. Psychology\u2019s contribution, as Freud saw it, lay in \u201cendeavouring to prove to the \u2018ego\u2019 of each one of us that he is not even master in his own house\u201d. LLMs could be argued to take the idea further still. At least one wing of Freud\u2019s house becomes an unoccupied \u201csmart home\u201d; the lights go on and off automatically, the smart thermostat opens windows and lowers blinds, the roomba roombas around. No master needed at all. \n\nUncanny as that may all be, though, it would be wrong to think that many people will take this latest decentring to heart. As far as everyday life is concerned, humankind has proved pretty resilient to Copernicus, Darwin and Freud. People still believe in gods and souls and specialness with little obvious concern for countervailing science. They could well adapt quite easily to the pseudocognitive world, at least as far as philosophical qualms are concerned. \nYou do not have to buy Freud\u2019s explanation of the unsettling effect of the uncanny in terms of the effort the mind expends on repressing childish animism to think that not worrying and going with the animistic flow will make a world populated with communicative pseudo-people a surprisingly comfortable one. People may simultaneously recognise that something is not alive and treat it as if it were. Some will take this too far, forming problematic attachments that Freud would have dubbed fetishistic. But only a few sensitive souls will find themselves left behind staring into an existential\u2014but personal\u2014abyss opened up by the possibility that their seeming thought is all for naught. \nNew gold dream\nWhat if Mr Ag\u00fcera y Arcas is right, though, and that which science deems lifeless is, in some cryptic, partial and emergent way, effectively animate? Then it will be time to do for AI some of what Freud thought he was doing for humans. Having realised that the conscious mind was not the whole show, Freud looked elsewhere for sources of desire that for good or ill drove behaviour. Very few people now subscribe to the specific Freudian explanations of human behaviour which followed. But the idea that there are reasons why people do things of which they are not conscious is part of the world\u2019s mental furniture. The unconscious is probably not a great model for whatever it is that provides LLMs with an apparent sense of meaning or an approximation of agency. But the sense that there might be something below the AI surface which needs understanding may prove powerful. \nThere might be something below the AI surface which needs understandingDr Bender and those who agree with her may take issue with such notions. But they might find that they lead to useful actions in the field of \u201cAI ethics\u201d. Winkling out non-conscious biases acquired in the pre-verbal infancy of training; dealing with the contradictions behind hallucinations; regularising rogue desires: ideas from psychotherapy might be seen as helpful analogies for dealing with the pseudocognitive AI transition even by those who reject all notion of an AI mind. A concentration on the relationship between parents, or programmers, and their children could be welcome, too. What is it to bring up an AI well? What sort of upbringing should be forbidden? To what extent should the creators of AIs be held responsible for the harms done by their creation? \nAnd human desires may need some inspection, too. Why are so many people eager for the sort of intimacy an LLM might provide? Why do many influential humans seem to think that, because evolution shows species can go extinct, theirs is quite likely to do so at its own hand, or that of its successor? And where is the determination to turn a  superhuman rationality into something which does not merely stir up the economy, but changes history for the better?\u25a0", "description": "Expect changes in the way people access knowledge, relate to knowledge and think about themselves", "ogDescription": "Expect changes in the way people access knowledge, relate to knowledge and think about themselves", "imageUrl": "https://www.economist.com/media-assets/image/20230422_ESD001.jpg", "imageHeight": 720, "imageWidth": 1280, "datePublished": "2023-04-20T10:57:02Z", "dateModified": "2023-04-20T18:50:57Z", "dateCreated": "2023-04-19T14:49:25Z", "isPrintArticle": true, "printEdition": "2023-04-22T00:00:00Z", "copyrightYear": 2023, "dateline": "BERKELEY AND BERLIN", "inLanguage": "en", "interactive": false, "scripts": [], "css": []}, "sectionArticles": [{"id": "/content/re6vv2c3kp32g0823hf6hmtqli1qnvas", "publication": [{"id": "/content/oq02trftu9mc92lsd5itom87ufgqp15q", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/4scc4vva7odlr6m76otihrom34b2lu80", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/fqi3r1ipeqmp3sn7rnquv7getubmh3v2", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/2q9c1n7p82uugfpdffl189mrkemql2f7", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/oebc7jcc10bin6t3e44svq590regi5bv", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/qk3633vlq3r42orc70a3haatrqk3f45s", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}, {"id": "/content/588urv90n1p5co985p8os2oho9o1gj26", "context": {"position": 440.12, "__typename": "Content"}, "__typename": "Content"}], "headline": "How AI could change computing, culture and the course of history", "url": {"canonical": "https://www.economist.com/essay/2023/04/20/how-ai-could-change-computing-culture-and-the-course-of-history", "__typename": "URL"}, "__typename": "Content"}]}