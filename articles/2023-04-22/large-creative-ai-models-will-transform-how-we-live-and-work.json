{"title": "Large, creative AI models will transform lives and labour markets", "subtitle": "They bring enormous promise and peril. In the first of three special articles we explain how they work", "authorName": "The Economist", "coverImageURL": "https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work/processed-images/1424/20230422_STD001.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "hashTag": "Science & technology", "publishDate": "Apr 22nd 2023", "contents": [{"role": "body", "text": "Since november 2022, when Openai, the company which makes Chatgpt, first opened the chatbot to the public, there has been little else that the tech elite has wanted to talk about. As this article was being written, the founder of a London technology company messaged your correspondent unprompted to say that this kind of ai is \u201cessentially all I\u2019m thinking about these days\u201d. He says he is in the process of redesigning his company, valued at many hundreds of millions of dollars, around it. He is not alone."}, {"role": "body", "text": "Chatgpt embodies more knowledge than any human has ever known. It can converse cogently about mineral extraction in Papua New Guinea, or about tsmc, a Taiwanese semiconductor firm that finds itself in the geopolitical crosshairs. gpt-4, the artificial neural network which powers Chatgpt, has aced exams that serve as gateways for people to enter careers in law and medicine in America. It can generate songs, poems and essays. Other \u201cgenerative ai\u201d models can churn out digital photos, drawings and animations."}, {"role": "body", "text": "Running alongside this excitement is deep concern, inside the tech industry and beyond, that generative ai models are being developed too quickly. gpt-4 is a type of generative ai called a large language model (llm). Tech giants like Alphabet, Amazon and Nvidia have all trained their own llms, and given them names like palm, Megatron, Titan and Chinchilla."}, {"role": "second", "text": "The lure grows greater"}, {"role": "body", "text": "The London tech boss says he is \u201cincredibly nervous about the existential threat\u201d posed by ai, even as he pursues it, and is \u201cspeaking with [other] founders about it daily\u201d. Governments in America, Europe and China have all started mulling new regulations. Prominent voices are calling for the development of artificial intelligence to be paused, lest the software somehow run out of control and damage, or even destroy, human society. To calibrate how worried or excited you should be about this technology, it helps first to understand where it came from, how it works and what the limits are to its growth."}, {"role": "body", "text": "The contemporary explosion of the capabilities of ai software began in the early 2010s, when a software technique called \u201cdeep learning\u201d became popular. Using the magic mix of vast datasets and powerful computers running neural networks on Graphics Processing Units (gpus), deep learning dramatically improved computers\u2019 abilities to recognise images, process audio and play games. By the late 2010s computers could do many of these tasks better than any human."}, {"role": "body", "text": "But neural networks tended to be embedded in software with broader functionality, like email clients, and non-coders rarely interacted with these ais directly. Those that did often described their experience in near-spiritual terms. Lee Sedol, one of the world\u2019s best players of Go, an ancient Chinese board game, retired from the game after Alphabet\u2019s neural-net-based AlphaGo software crushed him in 2016. \u201cEven if I become the number one,\u201d he said, \u201cthere is an entity that cannot be defeated.\u201d"}, {"role": "body", "text": "By working in the most human of mediums, conversation, Chatgpt is now allowing the internet-using public to experience something similar, a kind of intellectual vertigo caused by software which has improved suddenly to the point where it can perform tasks that had been exclusively in the domain of human intelligence."}, {"role": "body", "text": "Despite that feeling of magic, an llm is, in reality, a giant exercise in statistics. Prompt Chatgpt to finish the sentence: \u201cThe promise of large language models is that they\u2026\u201d and you will get an immediate response. How does it work?"}, {"role": "body", "text": "First, the language of the query is converted from words, which neural networks cannot handle, into a representative set of numbers (see graphic). gpt-3, which powered an earlier version of Chatgpt, does this by splitting text into chunks of characters, called tokens, which commonly occur together. These tokens can be words, like \u201clove\u201d or \u201care\u201d, affixes, like \u201cdis\u201d or \u201cised\u201d, and punctuation, like \u201c?\u201d. gpt-3\u2019s dictionary contains details of 50,257 tokens."}, {"role": "body", "text": "gpt-3 is able to process a maximum of 2,048 tokens at a time, which is around the length of a long article in The Economist. gpt-4, by contrast, can handle inputs up to 32,000 tokens long\u2014a novella. The more text the model can take in, the more context it can see, and the better its answers will be. There is a catch\u2014the required computation rises non-linearly with the length of the input, meaning slightly longer inputs need much more computing power."}, {"role": "body", "text": "The tokens are then assigned the equivalent of definitions by placing them into a \u201cmeaning space\u201d where words that have similar meanings are located in nearby areas."}, {"role": "body", "text": "The llm then deploys its \u201cattention network\u201d to make connections between different parts of the prompt. Someone reading our prompt, \u201cthe promise of large language models is that they\u2026\u201d, would know how English grammar works and understand the concepts behind the words in the sentence. It would be obvious to them which words relate to each other\u2014it is the model that is large, for example. An llm, however, must learn these associations from scratch during its training phase\u2014over billions of training runs, its attention network slowly encodes the structure of the language it sees as numbers (called \u201cweights\u201d) within its neural network. If it understands language at all, an llm only does so in a statistical, rather than a grammatical, way. It is much more like an abacus than it is like a mind."}, {"role": "body", "text": "Once the prompt has been processed, the llm initiates a response. At this point, for each of the tokens in the model\u2019s vocabulary, the attention network has produced a probability of that token being the most appropriate one to use next in the sentence it is generating. The token with the highest probability score is not always the one chosen for the response\u2014how the llm makes this choice depends on how creative the model has been told to be by its operators."}, {"role": "body", "text": "The llm generates a word and then feeds the result back into itself. The first word is generated based on the prompt alone. The second word is generated by including the first word in the response, then the third word by including the first two generated words, and so on. This process\u2014called autoregression\u2014repeats until the llm has finished"}, {"role": "body", "text": "Although it is possible to write down the rules for how they work, llms\u2019 outputs are not entirely predictable; it turns out that these extremely big abacuses can do things which smaller ones cannot, in ways which surprise even the people who make them. Jason Wei, a researcher at Openai, has counted 137 so-called \u201cemergent\u201d abilities across a variety of different llms."}, {"role": "body", "text": "The abilities that emerge are not magic\u2014they are all represented in some form within the llms\u2019 training data (or the prompts they are given) but they do not become apparent until the llms cross a certain, very large, threshold in their size. At one size, an llm does not know how to write gender-inclusive sentences in German any better than if it was doing so at random. Make the model just a little bigger, however, and all of a sudden a new ability pops out. gpt-4 passed the American Uniform Bar Examination, designed to test the skills of lawyers before they become licensed, in the 90th percentile. The slightly smaller gpt-3.5 flunked it."}, {"role": "body", "text": "Emergent abilities are exciting, because they hint at the untapped potential of llms. Jonas Degrave, an engineer at DeepMind, an ai research company owned by Alphabet, has shown that Chatgpt can be convinced to act like the command line terminal of a computer, appearing to compile and run programs accurately. Just a little bigger, goes the thinking, and the models may suddenly be able to do all manner of useful new things. But experts worry for the same reason. One analysis shows that certain social biases emerge when models become large. It is not easy to tell what harmful behaviours might be lying dormant, waiting for just a little more scale in order to be unleashed."}, {"role": "second", "text": "Process the data"}, {"role": "body", "text": "The recent success of llms in generating convincing text, as well as their startling emergent abilities, is due to the coalescence of three things: gobsmacking quantities of data, algorithms capable of learning from them and the computational power to do so (see chart). The details of gpt-4\u2019s construction and function are not yet public, but those of gpt-3 are, in a paper called \u201cLanguage Models are Few-Shot Learners\u201d, published in 2020 by Openai."}, {"role": "image", "imageURL": "https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work/images/20230422_WOC930/20230422_WOC930-Artboard_1.png", "imageWidth": 672, "imageHeight": 946}, {"role": "body", "text": "Before it sees any training data, the weights in gpt-3\u2019s neural network are mostly random. As a result, any text it generates will be gibberish. Pushing its output towards something which makes sense, and eventually something that is fluent, requires training. gpt-3 was trained on several sources of data, but the bulk of it comes from snapshots of the entire internet between 2016 and 2019 taken from a database called Common Crawl. There\u2019s a lot of junk text on the internet, so the initial 45 terabytes were filtered using a different machine-learning model to select just the high-quality text: 570 gigabytes of it, a dataset that could fit on a modern laptop. In addition, gpt-4 was trained on an unknown quantity of images, probably several terabytes. By comparison AlexNet, a neural network that reignited image-processing excitement in the 2010s, was trained on a dataset of 1.2m labelled images, a total of 126 gigabytes\u2014less than a tenth of the size of gpt-4\u2019s likely dataset."}, {"role": "body", "text": "To train, the llm quizzes itself on the text it is given. It takes a chunk, covers up some words at the end, and tries to guess what might go there. Then the llm uncovers the answer and compares it to its guess. Because the answers are in the data itself, these models can be trained in a \u201cself-supervised\u201d manner on massive datasets without requiring human labellers."}, {"role": "body", "text": "The model\u2019s goal is to make its guesses as good as possible by making as few errors as possible. Not all errors are equal, though. If the original text is \u201cI love ice cream\u201d, guessing \u201cI love ice hockey\u201d is better than \u201cI love ice are\u201d. How bad a guess is is turned into a number called the loss. After a few guesses, the loss is sent back into the neural network and used to nudge the weights in a direction that will produce better answers."}, {"role": "second", "text": "Trailblazing a daze"}, {"role": "body", "text": "The llm\u2019s attention network is key to learning from such vast amounts of data. It builds into the model a way to learn and use associations between words and concepts even when they appear at a distance from each other within a text, and it allows it to process reams of data in a reasonable amount of time. Many different attention networks operate in parallel within a typical llm and this parallelisation allows the process to be run across multiple gpus. Older, non-attention-based versions of language models would not have been able to process such a quantity of data in a reasonable amount of time. \u201cWithout attention, the scaling would not be computationally tractable,\u201d says Yoshua Bengio, scientific director of Mila, a prominent AI research institute in Quebec."}, {"role": "body", "text": "The sheer scale at which llms can process data has been driving their recent growth. gpt-3 has hundreds of layers, billions of weights, and was trained on hundreds of billions of words. By contrast, the first version of gpt, created five years ago, was just one ten-thousandth of the size."}, {"role": "body", "text": "But there are good reasons, says Dr Bengio, to think that this growth cannot continue indefinitely. The inputs of llms\u2014data, computing power, electricity, skilled labour\u2014cost money. Training gpt-3, for example, used 1.3 gigawatt-hours of electricity (enough to power 121 homes in America for a year), and cost Openai an estimated $4.6m. gpt-4, which is a much larger model, will have cost disproportionately more (in the realm of $100m) to train. Since computing-power requirements scale up dramatically faster than the input data, training llms gets expensive faster than it gets better. Indeed, Sam Altman, the boss of Openai, seems to think an inflection point has already arrived. On April 13th he told an audience at the Massachusetts Institute of Technology: \u201cI think we\u2019re at the end of the era where it\u2019s going to be these, like, giant, giant models. We\u2019ll make them better in other ways.\u201d"}, {"role": "body", "text": "But the most important limit to the continued improvement of llms is the amount of training data available. gpt-3 has already been trained on what amounts to all of the high-quality text that is available to download from the internet. A paper published in October 2022 concluded that \u201cthe stock of high-quality language data will be exhausted soon; likely before 2026.\u201d There is certainly more text available, but it is locked away in small amounts in corporate databases or on personal devices, inaccessible at the scale and low cost that Common Crawl allows."}, {"role": "body", "text": "Computers will get more powerful over time, but there is no new hardware forthcoming which offers a leap in performance as large as that which came from using gpus in the early 2010s, so training larger models will probably be increasingly expensive\u2014perhaps why Mr Altman is not enthused by the idea. Improvements are possible, including new kinds of chips such as Google\u2019s Tensor Processing Unit, but the manufacturing of chips is no longer improving exponentially through Moore\u2019s law and shrinking circuits."}, {"role": "body", "text": "There will also be legal issues. Stability ai, a company which produces an image-generation model called Stable Diffusion, has been sued by Getty Images, a photography agency. Stable Diffusion\u2019s training data comes from the same place as gpt-3 and gpt-4, Common Crawl, and it processes it in very similar ways, using attention networks. Some of the most striking examples of ai\u2019s generative prowess have been images. People on the internet are now regularly getting caught up in excitement about apparent photos of scenes that never took place: the pope in a Balenciaga jacket; Donald Trump being arrested."}, {"role": "body", "text": "Getty points to images produced by Stable Diffusion which contain its copyright watermark, suggesting that Stable Diffusion has ingested and is reproducing copyrighted material without permission (Stability AI has not yet commented publicly on the lawsuit). The same level of evidence is harder to come by when examining Chatgpt\u2019s text output, but there is no doubt that it has been trained on copyrighted material. Openai will be hoping that its text generation is covered by \u201cfair use\u201d, a provision in copyright law that allows limited use of copyrighted material for \u201ctransformative\u201d purposes. That idea will probably one day be tested in court."}, {"role": "second", "text": "A major appliance"}, {"role": "body", "text": "But even in a scenario where llms stopped improving this year, and a blockbuster lawsuit drove Openai to bankruptcy, the power of large language models would remain. The data and the tools to process it are widely available, even if the sheer scale achieved by Openai remains expensive."}, {"role": "body", "text": "Open-source implementations, when trained carefully and selectively, are already aping the performance of gpt-4. This is a good thing: having the power of llms in many hands means that many minds can come up with innovative new applications, improving everything from medicine to the law."}, {"role": "body", "text": "But it also means that the catastrophic risk which keeps the tech elite up at night has become more imaginable. llms are already incredibly powerful and have improved so quickly that many of those working on them have taken fright. The capabilities of the biggest models have outrun their creators\u2019 understanding and control. That creates risks, of all kinds. "}]}