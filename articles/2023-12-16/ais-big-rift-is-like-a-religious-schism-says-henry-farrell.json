{"coverImageURL": "https://www.economist.com/media-assets/image/20231216_BID001.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "AI\u2019s big rift is like a religious schism, says Henry Farrell", "subtitle": "In this doctrinal dust-up, very smart people are saying very strange things", "hashTag": "By Invitation", "authorName": "The Economist", "publishDate": "2023-12-12T15:34:29Z", "contents": [{"role": "body", "text": "TWO CENTURIES ago Henri de Saint-Simon, a French utopian, proposed a new religion, worshipping the godlike force of progress, with Isaac Newton as its chief saint. He believed that humanity\u2019s sole uniting interest, \u201cthe progress of the sciences\u201d, should be directed by the \u201celect of humanity\u201d, a 21-member \u201cCouncil of Newton\u201d. Friedrich Hayek, a 20th-century economist, later gleefully described how this ludicrous \u201creligion of the engineers\u201d collapsed into a welter of feuding sects. "}, {"role": "body", "text": "Today, the engineers of artificial intelligence (AI) are experiencing their own religious schism. One sect worships progress, canonising Hayek himself. The other is gripped by terror of godlike forces. Their battle has driven practical questions to the margins of debate."}, {"role": "body", "text": "Both cults are accidental by-products of science fiction. In 1993 Vernor Vinge drew on computer science and his fellow science-fiction writers to argue that ordinary human history was drawing to a close. We would surely create superhuman intelligence sometime within the next three decades, leading to a \u201cSingularity\u201d, in which AI would start feeding on itself. The future might be delightful or awful, depending on whether machines enhanced human intelligence or displaced it. "}, {"role": "body", "text": "Some were optimistic. The futurist Ray Kurzweil wrote an enormous tome, \u201cThe Singularity is Near\u201d, predicting a cusp in 2045. We humans would become immortal, spreading intelligence throughout the universe, and eventually merging into God. For all its statistics and exponentials, the book prophesied \u201cthe Rapture of the Nerds\u201d, as one unkind critic called it. Its title really should have been \u201cThe Singularity is Nigh\u201d."}, {"role": "body", "text": "Others feared the day of judgment. Eliezer Yudkowsky, a self-taught AI researcher, was deeply influenced by Mr Vinge\u2019s ideas. He fathered Silicon Valley\u2019s \u201crationalist\u201d movement, which sought to improve human reasoning and stop AI destroying humankind."}, {"role": "body", "text": "Rationalists believed that Bayesian statistics and decision theory could de-bias human thinking and model the behaviour of godlike intelligences. They revelled in endless theoretical debates, like medieval Christian philosophers disputing the nature of angels, applying amateur game theory instead of Aristotelian logic. Sometimes their discussions were less erudite. Mr Yudkowsky popularised his ideas in a 660,000-word fan-fiction epic, \u201cHarry Potter and the Methods of Rationality\u201d."}, {"role": "body", "text": "Rationalists feared that superhuman AIs wouldn\u2019t have our best interests at heart. One notorious thought experiment\u2014a modern version of Pascal\u2019s wager, dubbed \u201cRoko\u2019s basilisk\u201d\u2014claimed that logic dictated that future divine intelligences would torture anyone who had known that AI was possible and hadn\u2019t devoted themselves to bringing it into existence. AIs might also use their awesome reasoning powers to escape any limits that humans imposed on them, creating an \u201cx risk\u201d (existential risk) to human survival."}, {"role": "body", "text": "Rationalism explains why AI pioneers became obsessed with x risk. Sam Altman, Elon Musk and others founded OpenAI, the creator of ChatGPT, as a non-profit so that it wouldn\u2019t duck the dangers of machine intelligence. But the incentives shifted as the funding flooded in. Some OpenAI staffers feared that their employer cared more about the opportunities than the dangers and defected to found Anthropic, a rival AI firm. More recently, clashes over AI risk, money and power reportedly led to the fracture between Mr Altman and his board."}, {"role": "body", "text": "If rationalists are frustrated by Silicon Valley\u2019s profit model, Silicon Valley is increasingly frustrated by rationalism. Marc Andreessen, the co-founder of Andreessen Horowitz, a venture-capital firm, fulminated in June that the extremist AI-risk \u201ccult\u201d was holding back an awesome AI-augmented future, in which humanity could reach for the stars."}, {"role": "body", "text": "This backlash is turning into its own religion of the engineers. Grimes, a musician and Silicon Valley icon, marvels that AI engineers are \u201cdesigning the initial culture of the universe\u201d. She calls for a \u201cCouncil of Elrond\u201d (this conclave a nod to \u201cThe Lord of the Rings\u201d) comprising the \u201cheads of key AI companies and others who understand it\u201d to set AI policy. Grimes met Mr Musk, the father of her children, through a shared joke about Roko\u2019s basilisk."}, {"role": "body", "text": "In October Mr Andreessen published his own \u201cTechno-Optimist Manifesto\u201d to wide acclaim from Silicon Valley entrepreneurs. In it, he takes aim at a decades-long \u201cdemoralisation campaign\u2026against technology and life\u201d, under various names including \u201csustainable development goals\u201d, \u201csocial responsibility\u201d, \u201ctrust and safety\u201d and \u201ctech ethics\u201d. Efforts to decelerate AI \u201cwill cost human lives\u201d and are thus tantamount to \u201cmurder\u201d. "}, {"role": "body", "text": "Mr Andreessen\u2019s manifesto is a Nicene creed for the cult of progress: the words \u201cwe believe\u201d appear no less than 113 times in the text. His list of the \u201cpatron saints\u201d of techno-optimism begins with Based Beff Jezos, the social-media persona of a former Google engineer who claims to have founded \u201ceffective accelerationism\u201d, a self-described \u201cmeta-religion\u201d which puts its faith in the \u201ctechnocapital Singularity\u201d. "}, {"role": "body", "text": "Our future is currently being built around Mr Vinge\u2019s three-decades-old essay, a work that only Silicon Valley thinkers and science-fiction fans have read. Warring cults dispute whether engineers are as gods, or just unwitting Dr Frankensteins. "}, {"role": "body", "text": "This schism is an attention-sucking black hole that makes its protagonists more likely to say and perhaps believe stupid things. Of course, many AI-risk people recognise that there are problems other than the Singularity, but it\u2019s hard to resist its relentless gravitational pull. Before Mr Andreessen was fully dragged past the event horizon, he made more nuanced arguments about engineers\u2019 humility and addressing the problems of AI as they arose."}, {"role": "body", "text": "But we need even more to listen to other people. Last month, at Rishi Sunak\u2019s global AI-policy summit, Mr Musk pontificated about the need for an \u201coff switch\u201d for hostile AI. The main event was all about x risk and AI\u2019s transformative promise, consigning other questions to a sideshow dubbed the \u201cAI Fringe\u201d. "}, {"role": "body", "text": "At the same time, Rachel Coldicutt, a British tech thinker, was putting together a \u201cFringe of the Fringe\u201d, where a much more diverse group of thinkers debated the topics that hadn\u2019t made the main agenda: communities, transparency, power. They didn\u2019t suggest a Council of the Elect. Instead, they proposed that we should \u201cmake AI work for eight billion people, not eight billionaires\u201d. It might be nice to hear from some of those 8bn voices.\u25a0"}, {"role": "body", "text": "Henry Farrell is a professor of international affairs and democracy at Johns Hopkins University, and co-author of \u201cUnderground Empire: How America Weaponized the World Economy\u201d."}], "id": 12}