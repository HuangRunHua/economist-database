{"coverImageURL": "https://www.economist.com/media-assets/image/20230617_BRD001.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "How to make Britain\u2019s AI dreams reality", "subtitle": "Rishi Sunak\u2019s bet that Britain can prosper from AI requires a new approach", "hashTag": "Britain", "authorName": "The Economist", "publishDate": "2023-06-14T16:55:45Z", "contents": [{"role": "body", "text": "RISHI SUNAK dreams of Britain becoming an AI superpower. The prime minister says the technology, the subject of intense global interest thanks to successes of large language models such as GPT-4, could unlock economic growth and improve sclerotic public services. AI-related announcements these days gush from Downing Street faster than commentators can keep up. In March Jeremy Hunt, the chancellor, vowed to spend \u00a31bn ($1.3bn) over five years on AI and supercomputing. In May Mr Sunak met the bosses of leading AI companies in London. On June 7th, while visiting Joe Biden in Washington, he said that Britain would host the \u201cfirst global summit on Artificial Intelligence\u201d this autumn."}, {"role": "image", "imageURL": "https://www.economist.com/media-assets/image/20230617_BRC541.png", "imageWidth": 608.0, "imageHeight": 662.0, "imageDescription": ""}, {"role": "body", "text": "His broadest ambitions are well placed. AI has great potential, and Britain has an edge that could help it to prosper. The country is arguably the foremost location, outside China and America, to start a new tech company (see chart 1). It is home to important AI outfits, most notably DeepMind, an AI research lab owned by Alphabet, an American tech giant, and Stability AI, a generative-AI startup, both in London. Its excellent universities churn out capable graduates who are keen to toil in AI. In London, too, it has a globally appealing city that draws investors and high-skilled migrants."}, {"role": "body", "text": "Data collected by its public bodies\u2014crucially that from the enormous National Health Service (NHS), for example on drug-use outcomes, hospital logistics, or scans of the body under different conditions\u2014could provide a goldmine for training health-focused AI. The government also has a decent record of finding ways to use tech well. Just over a decade ago it launched the Government Digital Service, which digitised public services such as the issuing of passports or driving licences. That has been copied by governments around Europe and in America."}, {"role": "body", "text": "But for all the well-intentioned zest for the big new thing, Mr Sunak\u2019s government has yet to confront reality: enormous hurdles still block Britain\u2019s path towards AI success. AI systems are built from three ingredients: computation, clean datasets and the work of people who know how to wrangle vast quantities of both. A successful industry, in turn, needs the right regulation. Britain has serious difficulties to overcome in all those areas, and especially in the first two."}, {"role": "image", "imageURL": "https://www.economist.com/media-assets/image/20230617_BRC521.png", "imageWidth": 608.0, "imageHeight": 701.0, "imageDescription": ""}, {"role": "body", "text": "The most pressing problem is over \u201ccompute\u201d, the term AI researchers use for the vital infrastructure, lots of computing power, required to train the new sort of AI models. None of the big three cloud-computing companies\u2014Amazon, Google, Microsoft\u2014has built a large, advanced cluster of graphical processing units (GPUs) for compute to happen at scale in Britain (see chart 2). Only Oracle, a relative newcomer to the field, offers a cluster. This is in part because of Britain\u2019s smallish domestic market and its lack of access to the large one on its doorstep."}, {"role": "body", "text": "The fate of DeepMind, the country\u2019s most hopeful AI company, illustrates the compute problem. It had about 80 staff, all in London, when bought by Google (now Alphabet) in 2014. Today it is vastly bigger, with over 15% of its employees in America, mostly at Alphabet\u2019s headquarters, according to information on LinkedIn, a social-media platform. For Demis Hassabis, one of DeepMind\u2019s founders, this growth couldn\u2019t have happened with domestic resources alone: the pressing reason for selling to Google was the need to access the compute for training models. Today, DeepMind trains them in Oklahoma. What it faced roughly a decade ago persists today. Pitifully little has been done to tackle the shortfall. The lack of access to compute remains the biggest problem for AI growth, and for winning the wider economic benefits of Mr Sunak\u2019s dreams."}, {"role": "body", "text": "Politicians say that they are acting on this. Mr Hunt says he will spend \u00a3900m on a supercomputer, probably at the Edinburgh Parallel Computing Centre, \u201cbecause AI needs computing horsepower\u201d. The EPCC is indeed world class in supercomputing for scientific research. But, sadly, not all such horsepower is created equal. The new computer won\u2019t be ready before 2026 and the centre has no experience in building the kinds of GPU clusters used to train large AI models. And whereas the cloud clusters provided by Amazon, Google and Microsoft (who are also known as hyperscalers) are routinely updated with the latest chips, the EPCC, in contrast, will be stuck with whatever GPUs it can obtain now. It will then live with them until 2031, when its funding runs out. That is an eternity in AI time."}, {"role": "second", "text": "Beasts with horsepower"}, {"role": "body", "text": "Mark Parsons, an eminent computer scientist who runs the EPCC, is right to say supercomputers and GPU clusters are increasingly similar beasts, but even he accepts that the government plan has disadvantages. \u201cThe hyperscalers pride themselves in continuously updating their GPUs,\u201d he concedes, adding that the cost of doing that is too high for others to match. Others are less polite. For the government to claim a single, powerful computer in Edinburgh would solve Britain\u2019s compute woes is \u201cborderline dishonest,\u201d says a well-connected techie who understands the mix of data, compute and skills required."}, {"role": "body", "text": "An alternative option exists: renting compute. No companies or government agencies are entirely locked out from using AI. Anyone (at least when a global shortage of chips eventually eases) may rent time on cloud supercomputers used to train models. Anyone can download Common Crawl, an internet-scale database on which GPT-4 was trained, and start training a model. And anyone can use GPT-4 or a host of excellent open-source models to generate text or code."}, {"role": "body", "text": "\u201cCompute is not like oil,\u201d notes the techie. \u201cYou can call Amazon and rent it. It\u2019s a problem that money solves in perfectly continuous increments. It\u2019s not this magical thing that if you don\u2019t buy it you can\u2019t have,\u201d he says. Some companies do exactly this. The boss of Stability, Emad Mostaque, says his firm in London trains its models on Amazon\u2019s compute clusters based in Ohio and Virginia, for example."}, {"role": "body", "text": "The trouble is that Stability\u2019s behaviour is more exception than rule. Too often, British officials or companies require\u2014for reasons of politics, national security, privacy or something else\u2014that their data remain in the country. Neither the Ministry of Defence nor the NHS, for example, is about to upload sensitive data to foreign clouds. The boss of one large tech company with several public-sector contracts describes going \u201con bended knee\u201d to the hyperscalers, begging for access to compute in Britain. He was offered GPU time in the Netherlands or Ireland. But without local GPUs, he is not permitted to help his government customers train or run AI models based on their unique datasets."}, {"role": "body", "text": "Nor is sensitivity about data the only downside to renting compute abroad. Being physically close to compute at home brings real benefits. AI engineers and companies gain expertise by experimenting regularly on it. Techies seeking innovations need hands-on time. \u201cA country generates large benefits beyond access from having technology assets physically located there. \u2018Learning by doing\u2019 and the compounding of process knowledge is key to having a vibrant deep tech ecosystem and the high value jobs and companies that come with it,\u201d says Matt Clifford, chair of the Advanced Research and Invention Agency, a government skunkworks that helps to fund research in tech."}, {"role": "body", "text": "The most ambitious progress, therefore, depends on getting hyperscalers to set up GPU clusters in Britain. So how to do that? In the first instance, says one tech boss, Mr Sunak should know better what to ask for. He could start by launching a \u201cglobal lobbying unit\u201d to press for Amazon, Google or Microsoft to set up shop. The government should consider what hyperscalers would need to build in Britain."}, {"role": "body", "text": "Building entire new datacentres is not necessary. Instead Amazon, Google or Microsoft could replace servers in their existing (older style) British-based centres with ones that include the new chips produced by Nvidia, ideally the latest A100 or H100 models. Obtaining those chips may be the biggest problem in the short term, given a global supply crunch. "}, {"role": "body", "text": "Another challenge would be ensuring sufficient supplies of electricity, at low enough cost (and ideally green), because training AI models devours a lot of power. Such tasks don\u2019t look insurmountable, even if there would not be a quick fix. (Though it is hard to imagine it would take longer than building Mr Hunt\u2019s supercomputer). In the meantime Britain will have to limit itself to using foreign compute."}, {"role": "body", "text": "The longer the delay, however, the lower the chances of success. Without hyperscale GPU clusters, another set of British companies misses out: those attempting to supply picks and shovels in the AI boom. Nigel Toon, the boss of Graphcore, a young British company based in Bristol which makes AI chips, notes that his American competitors have great advantages that he lacks in selling their products to local, big stacks of compute."}, {"role": "body", "text": "Unsurprisingly, he also wants the new supercomputer in Edinburgh to favour British suppliers like his firm. The hour grows late, though. Sequoia, one of Graphcore\u2019s biggest investors, wrote down the value of its stake to zero in April. Meta, another American tech giant, has already scooped up some of the Graphcore team. The Bristol firm has plenty of cash in the bank, but desperately needs to get its chips into data centres."}, {"role": "body", "text": "After the difficulty of the compute desert, the other challenges look more manageable. One priority is improving the datasets available for AI developers. Data generated by public agencies should be the most appealing raw material for those working on AI. Unfortunately, they are too often a mess, including those within the NHS. Data to do with welfare are no better. Officials say that the computer systems running the Department for Work and Pensions are so feeble, for example, that six months are needed to adjust recipients\u2019 benefits for inflation. Trying to build BenefitsGPT atop a creaking 20th-century infrastructure looks like a fool\u2019s errand."}, {"role": "body", "text": "At least cleaning up the valuable datasets is within the control of the government. Officials could also look for benefits from generating new ones. \u201cStates don\u2019t leverage their only advantage: the sovereign right to produce data about things companies don\u2019t have,\u201d says Benjamin Bratton, who has written a book on the state\u2019s relationship with technology. He observes that states have the means to \u201cproduce models of their societies\u201d, but Britain\u2019s government (like most) lags behind tech companies in being able to model its own people\u2019s behaviour, the country\u2019s environment and its resources."}, {"role": "body", "text": "The NHS is particularly ripe for a data retrofit, though the road to doing this is littered with the bodies of politicians and companies who tried and failed. NHS IT, an effort to centralise medical records that was launched in 2002, ate up at least \u00a310bn before it was quietly dumped in 2011. New companies are popping up, attempting to solve the problem in a bitesized manner. At least one new startup wants to be paid to clean up government datasets, to make them useful for training AI models and to improve the more mundane services those data flows allow."}, {"role": "image", "imageURL": "https://www.economist.com/media-assets/image/20230617_BRD002.jpg", "imageWidth": 1383.0, "imageHeight": 896.0, "imageDescription": ""}, {"role": "body", "text": "The last \u00a3100m of Mr Hunt\u2019s \u00a31bn on AI may help with this. It is to be spent through a new Foundation Model Task-force. The outfit will focus on finding ways to train big models for the public sector and on making \u201cstrategic investments in the full AI stack,\u201d says an official. That is encouraging, even if the amount of money available is small; training a single large model once could eat up much of the funds Mr Hunt has set aside. \u201cSovereigns have the most interesting leverage on data, for sure,\u201d says the official. The task-force may direct some of money to kick-starting a data-hygiene industry, something for which there has not, to date, been a business model."}, {"role": "body", "text": "Making all of this happen in turn requires having enough skilled people around: British universities produce lots but, given the huge draw of Silicon Valley, there is also a steady flow of techies across the Atlantic. And as talent flows West, it takes its intellectual property along. \u201cThe reality is that the number of people who have seen GPUs melt because of 24/7 training jobs is very small,\u201d says Nathan Benaich of Air Street Capital, a London VC firm. \u201cCertainly they don\u2019t work for the government, and they can\u2019t be hired by the government to do a deal with the cloud vendors. These are the guys who know how it works.\u201d"}, {"role": "second", "text": "Neither Wild West nor rabbit hole"}, {"role": "body", "text": "One step to better retaining talent (as well as attracting investors) is to get the regulation of AI right. This means avoiding the path that the European Union is expected to follow, with ever-expanding swathes of horizontal rules, ones that cut across sectors, on how AI can be used safely. Britain\u2019s existing sector-by-sector, common-law approach, which would regulate different industries differently, looks like a better bet. Given global anxieties about the power and impact of AI, \u201cthere\u2019s an opportunity for Britain to move quickly and establish itself as a pragmatic place,\u201d says the tech boss who is struggling to access compute. Mr Sunak\u2019s summit in the autumn should be a good place to start."}, {"role": "body", "text": "\u201cI do buy the Sunak picture,\u201d says the tech boss. \u201cIn keeping with common law. You have these context-specific regulators. You don\u2019t have broad cross-sectoral statutory regulations. The EU is not going to do it; it has disappeared down the EU rabbit hole and is going to be down there for a couple of years. The US is going to be the Wild West. Britain is the one place that\u2019s going to combine that concern around ethics of models and their application with a deep pragmatism and openness to innovation. We have courts and regulators that are globally respected.\u201d"}, {"role": "body", "text": "Achieving more of this, and faster, also requires having more people in positions of power who understand computation. \u201cWe lack competence and confidence at the heart of government,\u201d says one adviser. \u201cThe people who run compute policy in the Department for Science, Innovation and Technology really just don\u2019t understand it. They don\u2019t understand the difference between general and specific computing.\u201d Hence the trumpeting of a supercomputer built by computer-science researchers as an answer to the country\u2019s AI woes."}, {"role": "body", "text": "For an example of what savvy techies with official support can do, look to the United Arab Emirates. Its government-backed Technology Innovation Institute used Amazon\u2019s cloud to train an open-source large language model called Falcon which is competitive with the best models trained by American companies, such as OpenAI. TII grants access to its compute to people with new ideas for training models and starting companies. Every nerd in the world has taken notice, and many now contribute their brain power to a project whose benefits\u2014such as attracting computer graduates to work on AI projects\u2014broadly accrue to the UAE."}, {"role": "body", "text": "The closest thing Britain has to this is Stability, the startup whose models generate photorealistic images. Its open source Stable Diffusion model produces pictures which have driven many on the internet into a frenzy (think fake pictures of Donald Trump\u2019s arrest, or the pope in a Balenciaga jacket). But the gravity of America\u2019s tech scene is exerting itself on Stability. The firm started in London but the majority of its employees are now in America, according to LinkedIn data. American backers provided all of its most recent funding. "}, {"role": "body", "text": "Mr Sunak\u2019s route to British AI superpowerdom will not run along paths where the most promising companies add most of their jobs overseas. Much remains to be done to make Britain more attractive, but the race has already begun and, for now, the country lags. \u25a0"}, {"role": "body", "text": "For more expert analysis of the biggest stories in Britain, sign up to Blighty, our weekly subscriber-only newsletter. "}], "id": 40}