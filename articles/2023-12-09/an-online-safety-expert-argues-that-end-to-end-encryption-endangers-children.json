{"coverImageURL": "https://www.economist.com/media-assets/image/20231202_BID003.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "An online-safety expert argues that end-to-end encryption endangers children", "subtitle": "Messaging platforms can and should balance privacy and welfare, says John Carr", "hashTag": "By Invitation", "authorName": "The Economist", "publishDate": "2023-12-06T15:47:38Z", "contents": [{"role": "body", "text": "ENCRYPTION TOOLS have been around for millennia. Julius Caesar used one form in his dispatches to his field commanders. Mary Queen of Scots used another to plot the overthrow of Queen Elizabeth I. And now some of the world\u2019s largest tech companies are integrating end-to-end encryption into their mass-messaging systems. "}, {"role": "body", "text": "Encryption allows people to send messages that can only be seen by the sender and receiver. This technology is a many-splendoured thing. But the problem I have with encryption is not a generalised one. It is the role it plays in enabling crimes against children, both online and offline. "}, {"role": "body", "text": "Currently, information that tech companies give to law enforcement contributes to thousands of arrests of suspected child-sex offenders each month, and protects an even larger number of children from sexual abuse. America\u2019s National Centre for Missing and Exploited Children (NCMEC), which distributes information to law-enforcement agencies worldwide on behalf of a group of national child-safety bodies, received 32m referrals for child sexual abuse last year. One company\u2014Meta\u2014accounted for 85% of these."}, {"role": "body", "text": "Despite this, Meta confirmed earlier this year that it will continue with its \u201cpivot to privacy\u201d. This involves rolling out end-to-end encryption across two of its largest communication platforms, Facebook Messenger and Instagram Direct (WhatsApp, which is also owned by Meta, is already end-to-end encrypted). The design of these platforms makes them vulnerable to exploitation by people looking to groom and sexually abuse children. Authentication of a new user\u2019s actual identity, in particular their age, is weak. If end-to-end encryption is introduced without appropriate safeguards, it will become a lot easier to commit and hide terrible crimes against minors."}, {"role": "body", "text": "Meta says its roll-out of end-to-end encryption will involve \u201crobust safety measures\u201d and that it will \u201ccontinue providing reports to law enforcement\u201d. But the company is blinding itself to the evidence. End-to-end encryption prevents the screening of data while it\u2019s transferred between devices, and so will make it harder for Meta to identify child sexual abuse on its platforms. The NCMEC estimates that 70% of Meta\u2019s reports\u2014or around 14m incidents of child sexual abuse\u2014could go undetected every year if the company rolls out end-to-end encryption without safety measures in place. The police cannot investigate perpetrators or rescue children if they don\u2019t have the reports in the first place. "}, {"role": "body", "text": "Proponents of end-to-end encryption tout its privacy credentials, as messages cannot be intercepted by third parties. While it\u2019s true that many people believe encryption will help them avoid persecution by totalitarian regimes, I fear that may only be true if it is an incompetent regime\u2014under the most advanced surveillance, people can be identified from the metadata associated with their messages. However, even if that were not the case, how can you tell parents in Toronto that you cannot do the maximum possible to protect their child because of what a tyrant might do with the same technology in Tehran? "}, {"role": "body", "text": "It is entirely possible to deploy tools alongside end-to-end encryption which allow patterns of child sexual abuse to be detected with a very high degree of accuracy. More than 99% of reports received each year by the NCMEC are generated by automated tools. The best-known programme, PhotoDNA, has been used at various points by Google, Facebook, Adobe, Reddit and X (formerly Twitter) since 2009. "}, {"role": "body", "text": "Through its Safety Tech Challenge Fund, the British government supported the development of proof-of-concept tools capable of detecting abusive material within encrypted environments. Consequently, tech experts and industry partners were able to show that it is technically feasible to detect abuse on encrypted services while maintaining user privacy. Client-side scanning is a good example of one of these tools. This technology scans messages in milliseconds before they enter the encryption zone, allowing child-sex-abuse material to be detected and addressed. "}, {"role": "body", "text": "This tool will only do one or more of three things: see and address already known abusive material; see and address images which are likely to feature child sex abuse; and see and address behaviour which is likely to indicate a child is being groomed for a sexual purpose. In the case of the latter two, if a human moderator checks it out and concludes it was a false alarm, that\u2019s it. These tools do not collect, store, process or in any meaningful way \u201csee\u201d anything else. No record is made, so no record can be kept. No investigation ensues. Nobody\u2019s time is wasted. Nobody\u2019s reputation is affected."}, {"role": "body", "text": "Why won\u2019t Meta introduce these technologies across Facebook Messenger and Instagram Direct Messages? The company will enjoy substantial business advantages from making the \u201cpivot to privacy\u201d, most obviously reduced overhead costs. In 2021 Meta spent $5bn and employed 40,000 people to work on \u201csafety and security\u201d. A large part of that would have been taken up by moderators, but encryption hugely reduces the need for such staff: you cannot moderate what you cannot see. The potential for Meta to be exposed to bad publicity over how much criminal content its systems pick up will also decline."}, {"role": "body", "text": "Unlike for Meta, there are no advantages for children. Quite the opposite. So the company must think again. It is not either/or: it\u2019s possible to keep the contents of messages hidden from prying eyes and protect kids at the same time. So why not?\u25a0"}, {"role": "body", "text": "John Carr is secretary of the Children\u2019s Charities\u2019 Coalition on Internet Safety. He is supporting Britain\u2019s Home Office with its campaign to work with tech companies to ensure their platforms are safe for children."}], "id": 12}