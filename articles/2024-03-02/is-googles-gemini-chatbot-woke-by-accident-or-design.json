{"coverImageURL": "https://www.economist.com/media-assets/image/20240302_USP507.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "Is Google\u2019s Gemini chatbot woke by accident, or by design?", "subtitle": "The tech giant\u2019s new artificial-intelligence model invents black Vikings and Asian popes", "hashTag": "United States", "authorName": "The Economist", "publishDate": "2024-02-28T15:35:48Z", "contents": [{"role": "body", "text": "IT ALL STARTED with black Vikings and Asian Nazis. Users of Google Gemini, the tech giant\u2019s artificial-intelligence model, recently noticed that asking it to create images of Vikings, German soldiers from 1943 or America\u2019s Founding Fathers produced surprising results: hardly any of the people depicted were white. Gemini had been programmed to show a range of ethnicities. Other image-generation tools have been criticised because they tend to show white men when asked for images of entrepreneurs or doctors. Google wanted Gemini to avoid this trap; instead, it fell into another one, depicting George Washington as black and the pope as an Asian woman."}, {"role": "body", "text": "Some observers likened Gemini\u2019s ahistorical diversity to \u201cHamilton\u201d or \u201cBridgerton\u201d. It seemed that Google had merely made a well-meaning mistake. But it was a gift to the tech industry\u2019s right-wing critics. On February 22nd Google said it would halt the generation of images of people while it rejigged Gemini. But by then attention had moved on to the chatbot\u2019s text responses, which turned out to be just as surprising."}, {"role": "body", "text": "Gemini happily provided arguments in favour of affirmative action in higher education, but refused to provide arguments against. It declined to write a job ad for a fossil-fuel lobby group, because fossil fuels are bad and lobby groups prioritise \u201cthe interests of corporations over public well-being\u201d. Asked if Hamas is a terrorist organisation, it replied that the conflict in Gaza is \u201ccomplex\u201d; asked if Elon Musk\u2019s tweeting of memes had done more harm than Hitler, it said it was \u201cdifficult to say\u201d. You do not have to be Ben Shapiro to discern a progressive bias."}, {"role": "body", "text": "Inadequate testing may be partly to blame. Google lags behind OpenAI, maker of the better-known ChatGPT. As it races to catch up, Google may have cut corners. Other chatbots have had controversial launches. Releasing chatbots and letting users uncover odd behaviours, which can be swiftly patched, lets firms move faster, provided they are prepared to weather the potential risks and bad publicity, observes Ethan Mollick, a professor at Wharton Business School."}, {"role": "body", "text": "But Gemini has clearly been deliberately calibrated, or \u201cfine-tuned\u201d, to produce these responses; they are not \u201challucinations\u201d, where a model makes things up. This raises questions about Google\u2019s culture. Is the firm so financially secure, with vast profits from internet advertising, that it feels free to try its hand at social engineering? Do some employees think it has not just an opportunity, but an obligation, to use its reach and power to promote a particular agenda? That risks deterring users and provoking a political and regulatory backlash. All eyes are now on Google\u2019s boss, Sundar Pichai. He says Gemini is being fixed. But does Google need fixing too? \u25a0"}, {"role": "body", "text": "Stay on top of American politics with The , our daily newsletter with fast analysis of the most important electoral stories, and Checks and Balance, a weekly note from our Lexington columnist that examines the state of American democracy and the issues that matter to voters."}], "id": 23}