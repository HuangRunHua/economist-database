{"coverImageURL": "https://www.economist.com/media-assets/image/20230318_WBD000.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "A battle royal is brewing over copyright and AI", "subtitle": "Beware the Napster precedent", "hashTag": "Business", "authorName": "The Economist", "publishDate": "2023-03-15T18:44:41Z", "contents": [{"role": "body", "text": "Consider two approaches in the music industry to artificial intelligence (AI). One is that of Giles Martin, son of Sir George Martin, producer of the Beatles. Last year, in order to remix the Fab Four\u2019s 1966 album \u201cRevolver\u201d, he used AI to learn the sound of each band member\u2019s instruments (eg, John Lennon\u2019s guitar) from a mono master tape so that he could separate them and reverse engineer them into stereo. The result is glorious. The other approach is not bad either. It is the response of Nick Cave, a moody Australian singer-songwriter, when reviewing lyrics written in his style by ChatGPT, an AI tool developed by a startup called OpenAI. \u201cThis song sucks,\u201d he wrote. \u201cWriting a good song is not mimicry, or replication, or pastiche, it is the opposite. It is an act of self-murder that destroys all one has strived to produce in the past.\u201d"}, {"role": "body", "text": "Mr Cave is unlikely to be impressed by the latest version of the algorithm behind ChatGPT, dubbed GPT-4, which OpenAI unveiled on March 14th. Mr Martin may find it useful. Michael Nash, chief digital officer at Universal Music Group, the world\u2019s biggest label, cites their examples as evidence of both excitement and fear about the AI behind content-creating apps like ChatGPT (for text) or Stable Diffusion (for images). It could help the creative process. It could also destroy or usurp it. Yet for recorded music at large, the coming of the bots brings to mind a seismic event in its history: the rapid rise and fall of Napster, a platform for sharing mainly pirated songs at the turn of the millennium. Napster was ultimately brought down by copyright law. For aggressive bot providers accused of riding roughshod over intellectual property (IP), Mr Nash has a simple message that sounds, from a music-industry veteran of the Napster era, like a threat. \u201cDon\u2019t deploy in the market and beg for forgiveness. That\u2019s the Napster approach.\u201d "}, {"role": "body", "text": "The main issue here is not AI-made parodies of Mr Cave or faux-Shakespearean sonnets. It is the oceans of copyrighted data the bots have siphoned up while being trained to create humanlike content. That information comes from everywhere: social-media feeds, internet searches, digital libraries, television, radio, banks of statistics and so on. Often, it is alleged, AI models plunder the databases without permission. Those responsible for the source material complain that their work is hoovered up without consent, credit or compensation. In short, some AI platforms may be doing with other media what Napster did with songs\u2014ignoring copyright altogether. The lawsuits have started to fly. "}, {"role": "body", "text": "It is a legal minefield with implications that extend beyond the creative industries to any business where machine-learning plays a role, such as self-driving cars, medical diagnostics, factory robotics and insurance-risk management. The European Union, true to bureaucratic form, has a directive on copyright that refers to data-mining (written before the recent bot boom). Experts say America lacks case history specific to generative AI. Instead, it has competing theories about whether or not data-mining without licences is permissible under the \u201cfair use\u201d doctrine. Napster also tried to deploy \u201cfair use\u201d as a defence in America\u2014and failed. That is not to say that the outcome will be the same this time. "}, {"role": "body", "imageURL": "https://www.youtube.com/embed/dctcfxw13AQ", "imageWidth": 640.0, "imageHeight": 360.0, "imageDescription": "", "text": ""}, {"role": "body", "text": "The main arguments around \u201cfair use\u201d are fascinating. To borrow from a masterclass on the topic by Mark Lemley and Bryan Casey in the Texas Law Review, a journal, use of copyrighted works is considered fair when it serves a valuable social purpose, the source material is transformed from the original and it does not affect the copyright owners\u2019 core market. Critics argue that AIs do not transform but exploit the entirety of the databases they mine. They claim that the firms behind machine learning abuse fair use to \u201cfree-ride\u201d on the work of individuals. And they contend that this threatens the livelihoods of the creators, as well as society at large if the AI promotes mass surveillance and the spread of misinformation. The authors weigh these arguments against the fact that the more access to training sets there is, the better AI will be, and that without such access there may be no AI at all. In other words, the industry might die in its infancy. They describe it as one of the most important legal questions of the century: \u201cWill copyright law allow robots to learn?\u201d "}, {"role": "body", "text": "An early lawsuit attracting attention is from Getty Images. The photography agency accuses Stability AI, which owns Stable Diffusion, of infringing its copyright on millions of photos from its collection in order to build an image-generating AI model that will compete with Getty. Provided the case is not settled out of court, it could set a precedent on fair use. An even more important verdict could come soon from America\u2019s Supreme Court in a case involving the transformation of copyrighted images of Prince, a pop idol, by the late Andy Warhol, an artist. Daniel Gervais, an IP expert at Vanderbilt Law School in Nashville, believes the justices may provide long-awaited guidance on fair use in general."}, {"role": "body", "text": "Scraping copyrighted data is not the only legal issue generative AI faces. In many jurisdictions copyright applies only to work created by humans, hence the extent to which bots can claim IP protection for the stuff they generate is another grey area. Outside the courtrooms the biggest questions will be political, including whether or not generative AI should enjoy the same liability protections for the content it displays as social-media platforms do, and to what extent it jeopardises data privacy."}, {"role": "second", "text": "The copyrighting is on the wall"}, {"role": "body", "text": "Yet the IP battle will be a big one. Mr Nash says creative industries should swiftly take a stand to ensure artists\u2019 output is licensed and used ethically in training AI models. He urges AI firms to \u201cdocument and disclose\u201d their sources. But, he acknowledges, it is a delicate balance. Creative types do not want to sound like enemies of progress. Many may benefit from AI in their work. The lesson from Napster\u2019s \u201creality therapy\u201d, as Mr Nash calls it, is that it is better to engage with new technologies than hope they go away. Maybe this time it won\u2019t take 15 years of crumbling revenues to learn it. \u25a0"}, {"role": "body", "text": "Read more from Schumpeter, our columnist on global business:How to stop the commoditisation of container shipping (Mar 9th)Lessons from Novo Nordisk on the stampede for obesity drugs (Mar 2nd)It\u2019s time for Alphabet to spin off YouTube (Feb 23rd)"}, {"role": "body", "text": "Also: How the Schumpeter column got its name"}], "id": 48}