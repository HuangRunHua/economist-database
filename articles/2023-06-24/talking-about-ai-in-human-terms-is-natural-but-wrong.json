{"coverImageURL": "https://www.economist.com/media-assets/image/20230624_CUD002.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "Talking about AI in human terms is natural\u2014but wrong", "subtitle": "When it comes to artificial intelligence, metaphors are often misleading", "hashTag": "Culture", "authorName": "The Economist", "publishDate": "2023-06-22T13:46:55Z", "contents": [{"role": "body", "text": "MY LOVE\u2019S LIKE a red, red rose. It is the east, and Juliet is the sun. Life is a highway, I wanna ride it all night long. Metaphor is a powerful and wonderful tool. Explaining one thing in terms of another can be both illuminating and pleasurable, if the metaphor is apt."}, {"role": "body", "text": "But that \u201cif\u201d is important. Metaphors can be particularly helpful in explaining unfamiliar concepts: imagining the Einsteinian model of gravity (heavy objects distort space-time) as something like a bowling ball on a trampoline, for example. But metaphors can also be misleading: picturing the atom as a solar system helps young students of chemistry, but the more advanced learn that electrons move in clouds of probability, not in neat orbits as planets do."}, {"role": "body", "text": "What may be an even more misleading metaphor\u2014for artificial intelligence (AI)\u2014seems to be taking hold. AI systems can now perform staggeringly impressive tasks, and their ability to reproduce what seems like the most human function of all, namely language, has ever more observers writing about them. When they do, they are tempted by an obvious (but obviously wrong) metaphor, which portrays ai programmes as conscious and even intentional agents. After all, the only other creatures which can use language are other conscious agents\u2014that is, humans."}, {"role": "body", "text": "Take the well-known problem of factual mistakes in potted biographies, the likes of which ChatGPT and other large language models (llms) churn out in seconds. Incorrect birthplaces, non-existent career moves, books never written: one journalist at The Economist was alarmed to learn that he had recently died. In the jargon of AI engineers, these are \u201challucinations\u201d. In the parlance of critics, they are \u201clies\u201d. "}, {"role": "body", "text": "\u201cHallucinations\u201d might be thought of as a forgiving euphemism. Your friendly local AI is just having a bit of a bad trip; leave him to sleep it off and he\u2019ll be back to himself in no time. For the \u201clies\u201d crowd, though, the humanising metaphor is even more profound: the AI is not only thinking, but has desires and intentions. A lie, remember, is not any old false statement. It is one made with the goal of deceiving others. ChatGPT has no such goals at all."}, {"role": "body", "text": "Humans\u2019 tendency to anthropomorphise things they don\u2019t understand is ancient, and may confer an evolutionary advantage. If, on spying a rustling in the bushes, you infer an agent (whether predator or spirit), no harm is done if you are wrong. If you assume there is nothing in the undergrowth and a leopard jumps out, you are in trouble. The all-too-human desire to smack or yell at a malfunctioning device comes from this ingrained instinct to see intentionality everywhere."}, {"role": "body", "text": "It is an instinct, however, that should be overridden when writing about AI. These systems, including those that seem to converse, merely take input and produce output. At their most basic level, they do nothing more than turn strings like 0010010101001010 into 1011100100100001 based on a set of instructions. Other parts of the software turn those 0s and 1s into words, giving a frightening\u2014but false\u2014sense that there is a ghost in the machine."}, {"role": "body", "text": "Whether they can be said to \u201cthink\u201d is a matter of philosophy and cognitive science, since plenty of serious people see the brain as a kind of computer. But it is safer to call what LLMs do \u201cpseudo-cognition\u201d. Even if it is hard on the face of it to distinguish the output from human activity, they are fundamentally different under the surface. Most importantly, cognition is not intention. Computers do not have desires. "}, {"role": "body", "text": "It can be tough to write about machines without metaphors. People say a watch \u201ctells\u201d the time, or that a credit-card reader which is working slowly is \u201cthinking\u201d while they wait awkwardly at the checkout. Even when machines are said to \u201cgenerate\u201d output, that cold-seeming word comes from an ancient root meaning to give birth. "}, {"role": "body", "text": "But AI is too important for loose language. If entirely avoiding human-like metaphors is all but impossible, writers should offset them, early, with some suitably bloodless phrasing. \u201cAn llm is designed to produce text that reflects patterns found in its vast training data,\u201d or some such explanation, will help readers take any later imagery with due scepticism. Humans have evolved to spot ghosts in machines. Writers should avoid ushering them into that trap. Better to lead them out of it.\u25a0"}, {"role": "body", "text": "Read more from Johnson, our columnist on language:Gestures are a subtle and vital form of communication (Jun 8th)As it spreads across the world, who owns English? (May 25th)The hazards of pronouncing foreign names on air (May 11th)"}, {"role": "body", "text": "\u201cWriting With Style\u201d, a new version of The Economist\u2018s style guide by Lane Greene, our Johnson columnist, is out now."}, {"role": "body", "text": "For more on the latest books, films, TV shows, albums and controversies, sign up to Plot Twist, our weekly subscriber-only newsletter"}], "id": 69}