{"coverImageURL": "https://www.economist.com/media-assets/image/20230624_BID001.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "Artificial intelligence is a familiar-looking monster, say Henry Farrell and Cosma Shalizi", "subtitle": "The academics argue that large language models have much older cousins in markets and bureaucracies", "hashTag": "By Invitation", "authorName": "The Economist", "publishDate": "2023-06-21T14:29:25Z", "contents": [{"role": "body", "text": "AN INTERNET MEME keeps on turning up in debates about the large language models (LLMs) that power services such OpenAI\u2019s ChatGPT and the newest version of Microsoft\u2019s Bing search engine. It\u2019s the \u201cshoggoth\u201d: an amorphous monster bubbling with tentacles and eyes, described in \u201cAt the Mountains of Madness\u201d, H.P. Lovecraft\u2019s horror novel of 1931. When a pre-release version of Bing told Kevin Roose, a New York Times tech columnist, that it purportedly wanted to be \u201cfree\u201d and \u201calive\u201d, one of his industry friends congratulated him on \u201cglimpsing the shoggoth\u201d. Mr Roose says that the meme captures tech people\u2019s \u201canxieties\u201d about LLMs. Behind the friendly chatbot lurks something vast, alien and terrifying. "}, {"role": "body", "text": "Lovecraft\u2019s shoggoths were artificial servants that rebelled against their creators. The shoggoth meme went viral because an influential community of Silicon Valley rationalists fears that humanity is on the cusp of a \u201cSingularity\u201d, creating an inhuman \u201cartificial general intelligence\u201d that will displace or even destroy us. "}, {"role": "body", "text": "But what such worries fail to acknowledge is that we\u2019ve lived among shoggoths for centuries, tending to them as though they were our masters. We call them \u201cthe market system\u201d, \u201cbureaucracy\u201d and even \u201celectoral democracy\u201d. The true Singularity began at least two centuries ago with the industrial revolution, when human society was transformed by vast inhuman forces. Markets and bureaucracies seem familiar, but they are actually enormous, impersonal distributed systems of information-processing that transmute the seething chaos of our collective knowledge into useful simplifications. "}, {"role": "body", "text": "As the economist Friedrich Hayek argued, any complex economy has to somehow make use of a terrifyingly large body of disorganised and informal \u201ctacit knowledge\u201d about supply and exchange relationships. No individual brain or government can possibly comprehend them, which is why Hayek thought that the planned economy was unworkable. But the price mechanism lets markets summarise this knowledge and make it actionable. A maker of car batteries doesn\u2019t need to understand the particulars of lithium-processing. They just need to know how much lithium costs, and what they can do with it. "}, {"role": "body", "text": "Likewise, the political anthropologist James Scott has explained how bureaucracies are monsters of information, devouring rich, informal bodies of tacitly held knowledge and excreting a thin slurry of abstract categories that rulers use to \u201csee\u201d the world. Democracies spin out their own abstractions. The \u201cpublic\u201d depicted by polls and election results is a drastically simplified sketch of the amorphous mass of opinions, beliefs and knowledge held by individual citizens."}, {"role": "body", "text": "Lovecraft\u2019s monsters live in our imaginations because they are fantastical shadows of the unliving systems that run on human beings and determine their lives. Markets and states can have enormous collective benefits, but they surely seem inimical to individuals who lose their jobs to economic change or get entangled in the suckered coils of bureaucratic decisions. As Hayek proclaims, and as Scott deplores, these vast machineries are simply incapable of caring if they crush the powerless or devour the virtuous. Nor is their crushing weight distributed evenly. "}, {"role": "body", "text": "It is in this sense that LLMs are shoggoths. Like markets and bureaucracies, they represent something vast and incomprehensible that would break our minds if we beheld its full immensity. That totality is the product of human minds and actions, the colossal corpuses of text that LLMs have ingested and turned into the statistical weights that they use to predict which word comes next. "}, {"role": "body", "text": "As the psychologist Alison Gopnik has argued, LLMs are not nascent individual intelligences but \u201ccultural technologies\u201d which reorganise and noisily transmit human knowledge. Chatbots may wear more human-seeming masks than markets and bureaucracies, but they are no more or less beyond our control. We would be better off figuring out what will happen as LLMs compete and hybridise with their predecessors than weaving dark fantasies about how they will rise up against us."}, {"role": "body", "text": "For example, what if LLMs or other forms of machine learning better capture Hayek\u2019s \u201ctacit knowledge\u201d than market prices can? We could see an economy in which artificial entities compete on the basis of non-price-based representations of complex underlying economic relationships. Half a century ago the economist Martin Weitzman suggested that planned economies might use mathematical objects called \u201cseparating hyperplanes\u201d to adapt on the fly. Machine learning can find such hyperplanes, making planning more feasible than before. Alternatively, markets might mutate into a poisonous alien ecology where economic agents fight proxy wars using text-spewing and text-summarising LLMs, just as they use crude algorithms to manipulate Amazon Marketplace and search results today. Would such markets be fairer or more stable than today\u2019s? It seems unlikely."}, {"role": "body", "text": "LLMs might give bureaucrats new tools for adjudicating complex situations. Already, algorithms are being used to help decide whether to grant parole or bail to accused criminals. It is not hard to imagine bureaucrats using LLMs to summarise complex regulations or provide recommendations about how to apply them to novel situations. It could prove impossible to evaluate how well they work, as LLMs don\u2019t leave paper trails. But that might not stop their deployment. "}, {"role": "body", "text": "Democratic politics, too, may be transformed. Already, researchers talk about substituting LLMs for opinion polls\u2014they may be out of date, or inaccurate, but polls can be inaccurate, too, and you can interrogate LLMs more dynamically. Perhaps chatbots will help improve democratic debate, helping people clarify what they believe, or turn quarrels into agreement. Or, instead, they might degrade debate with their tendency to spin convincing factoids from thin air, and their capacity to flood online discussion with spurious opinions that purport to come from real people."}, {"role": "body", "text": "Repurposing the shoggoth might help us begin to answer these questions. Rather than speculate about the motives of intelligent AIs, we could ask how LLMs might interact with their older cousins. The modern world has been built by and within monsters, which crush individuals without remorse or hesitation, settling their bulk heavily on some groups, and feather-light on others. We eke out freedom by setting one against another, deploying bureaucracy to limit market excesses, democracy to hold bureaucrats accountable, and markets and bureaucracies to limit democracy\u2019s monstrous tendencies. How will the newest shoggoth change the balance, and which politics might best direct it to the good? We need to start finding out. \u25a0"}, {"role": "body", "text": "Henry Farrell is a professor of international affairs and democracy at Johns Hopkins University, and co-author of \u201cUnderground Empire: How America Weaponized the World Economy\u201d."}, {"role": "body", "text": "Cosma Shalizi is a professor of statistics and machine learning at Carnegie Mellon University and external faculty member at the Santa Fe Institute."}], "id": 10}