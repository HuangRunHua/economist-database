{"coverImageURL": "https://www.economist.com/media-assets/image/20230715_BLP501.jpg", "coverImageWidth": 1280, "coverImageHeight": 720, "coverImageDescription": "", "title": "How AI image-generators work", "subtitle": "Some are getting good enough to fool humans", "hashTag": "The Economist explains", "authorName": "The Economist", "publishDate": "2023-07-10T16:10:25Z", "contents": [{"role": "body", "text": "THE FLURRY of images generated by artificial intelligence (AI) feels like the product of a thoroughly modern tool. In fact, computers have been at the easel for decades. In the early 1970s Harold Cohen, an artist, taught one to draw using an early AI system. \u201cAARON\u201d could instruct a robot to sketch black-and-white shapes on paper; within a decade Cohen had taught AARON to draw human figures. "}, {"role": "body", "text": "Today \u201cgenerative AI\u201d models put brush to virtual paper: publicly available apps, such as Midjourney and OpenAI\u2019s DALL-E, create images in seconds based on text prompts. The final products often dupe humans. In March AI-generated images of Donald Trump being handcuffed by police went viral online. And image generators are improving fast. How do they work\u2014and how are they refining their craft?"}, {"role": "body", "text": "Generative-AI models are a type of deep learning, a software technique that uses layers of interconnected nodes that loosely mimic the structure of the human brain. The models behind image-generators are trained on enormous datasets: LAION-5B, the largest publicly available one, contains 5.85bn tagged images. Datasets are often scraped from the internet, including from social-media platforms, stock-photo libraries and shopping websites. "}, {"role": "body", "text": "The most advanced image-generators typically use a type of generative AI known as a diffusion model. They add distorting visual \u201cnoise\u201d to images in the dataset\u2014making them look like an analogue TV still disrupted by static\u2014until the pictures are completely obscured. By learning how to undo the mess, the model can produce an image that is similar to the original. As it becomes better at recognising groups of pixels that correspond to particular visual concepts, it starts to compress, categorise and store this knowledge in a mathematical pocket of code known as the \u201clatent space\u201d."}, {"role": "body", "text": "Let\u2019s say you ask a generator app to create a picture of a hippopotamus. A model that has learned which types of pixel arrangement correlate to the word \u201chippopotamus\u201d (see picture, left) should be able to sample from its latent space to create a realistic image of the mammal. Adding more detail to the prompt\u2014for example, \u201ca renaissance-era oil painting of a green hippopotamus, somewhere along the river Nile\u201d (see picture, right)\u2014requires the model to source additional layers of visual detail, such as image style, texture, colour and location, and to combine them correctly. "}, {"role": "image", "imageURL": "https://www.economist.com/media-assets/image/20230715_BLP505.jpg", "imageWidth": 1280.0, "imageHeight": 720.0, "imageDescription": ""}, {"role": "body", "text": "The responses to complicated prompts can be erratic, particularly if the prompt is not clearly phrased or the scene it describes is not well represented in the training dataset. Even seemingly simple fare can trip models up. Human hands are often depicted with missing or extra fingers, or proportions that appear to bend the rules of physics. Because hands are usually less prominent than faces in photographs, there are smaller datasets for AI models to hone their technique on. Dodgy facial symmetry\u2014especially inconsistencies in colour and shape between eyes, teeth and ears\u2014is another sign of a machine\u2019s work. And image generators struggle with text, often creating non-existent letters or imaginary words. "}, {"role": "body", "text": "Developers can help models to learn from their mistakes by refining the datasets that they are learning from or by tweaking algorithms. Midjourney was recently updated to improve the way it generates hands. Rapid improvements mean that telling an AI-generated image from a real photograph or painting may soon become impossible. \u25a0"}], "id": 70}